#!/usr/bin/env python3
"""
æ”¹è¿›çš„FieldHunter - ä¿®å¤Perfectioné—®é¢˜
ä¸»è¦æ”¹è¿›ï¼š
1. å»æ‰Tolerant_PerfectionæŒ‡æ ‡
2. å¢åŠ è°ƒè¯•ä¿¡æ¯åˆ†æPerfectionä½çš„åŸå› 
3. æ”¹è¿›è¾¹ç•Œæ£€æµ‹å’Œè¯„ä¼°ç­–ç•¥
4. å¢åŠ è¯¦ç»†çš„åˆ†ææŠ¥å‘Š
"""

import os
import sys
import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Optional, Set, Union
from collections import defaultdict, Counter
import json
import random
from pathlib import Path
import argparse
from sklearn.metrics import f1_score, accuracy_score
from sklearn.cluster import DBSCAN
import warnings
from dataclasses import dataclass
import math
import glob

warnings.filterwarnings('ignore')


@dataclass
class FieldCandidate:
    """å­—æ®µå€™é€‰ç»“æ„"""
    start_offset: int
    end_offset: int
    field_type: str
    confidence: float
    pattern_consistency: float

    @property
    def length(self) -> int:
        return self.end_offset - self.start_offset

    def overlaps_with(self, other: 'FieldCandidate') -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸å¦ä¸€ä¸ªå­—æ®µå€™é€‰é‡å """
        return not (self.end_offset <= other.start_offset or self.start_offset >= other.end_offset)


def count_protocol_files(data_root: str = "../../Msg2", protocol_name: str = None) -> int:
    """ç»Ÿè®¡æŒ‡å®šåè®®çš„æ•°æ®æ–‡ä»¶æ•°é‡"""
    data_path = Path(data_root)

    if not data_path.exists():
        print(f"âš ï¸  è­¦å‘Š: æ•°æ®æ ¹ç›®å½• '{data_root}' ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤æ ·æœ¬æ•°é‡")
        return 100

    if protocol_name:
        # ç»Ÿè®¡ç‰¹å®šåè®®çš„æ•°æ®è¡Œæ•°
        csv_protocol_path = data_path / "csv" / protocol_name
        if csv_protocol_path.exists():
            total_rows = 0
            csv_files = list(csv_protocol_path.glob("*.csv"))
            for csv_file in csv_files:
                try:
                    df = pd.read_csv(csv_file)
                    total_rows += len(df)
                except Exception as e:
                    print(f"âš ï¸  è¯»å–æ–‡ä»¶å¤±è´¥ {csv_file}: {e}")
            print(f"ğŸ“ åè®® {protocol_name.upper()} æ•°æ®æ¡æ•°: {total_rows}")
            return total_rows
        else:
            print(f"âš ï¸  è­¦å‘Š: åè®®ç›®å½• '{csv_protocol_path}' ä¸å­˜åœ¨")
            return 0
    else:
        # ç»Ÿè®¡æ‰€æœ‰åè®®çš„å¹³å‡æ•°æ®è¡Œæ•°
        csv_path = data_path / "csv"
        if not csv_path.exists():
            print(f"âš ï¸  è­¦å‘Š: csvç›®å½• '{csv_path}' ä¸å­˜åœ¨")
            return 100

        total_rows = 0
        protocol_count = 0

        for protocol_dir in csv_path.iterdir():
            if protocol_dir.is_dir():
                protocol_rows = 0
                csv_files = list(protocol_dir.glob("*.csv"))
                for csv_file in csv_files:
                    try:
                        df = pd.read_csv(csv_file)
                        protocol_rows += len(df)
                    except Exception as e:
                        print(f"âš ï¸  è¯»å–æ–‡ä»¶å¤±è´¥ {csv_file}: {e}")

                total_rows += protocol_rows
                protocol_count += 1
                print(f"ğŸ“ åè®® {protocol_dir.name.upper()}: {protocol_rows} æ¡æ•°æ®")

        if protocol_count > 0:
            avg_rows = total_rows // protocol_count
            print(f"ğŸ“Š å¹³å‡æ¯ä¸ªåè®®æ•°æ®æ¡æ•°: {avg_rows}")
            return avg_rows
        else:
            return 100


class RealDataFieldHunterDataLoader:
    """ä½¿ç”¨çœŸå®æ•°æ®é›†çš„FieldHunteræ•°æ®åŠ è½½å™¨"""

    def __init__(self, data_root: str = "../../Msg2"):
        self.data_root = Path(data_root)
        self.txt_path = self.data_root / "txt"
        self.csv_path = self.data_root / "csv"

        # æ£€æŸ¥æ•°æ®ç›®å½•ç»“æ„
        self._validate_data_structure()

        # è·å–æ”¯æŒçš„åè®®åˆ—è¡¨
        self.supported_protocols = self._get_available_protocols()

    def _validate_data_structure(self):
        """éªŒè¯æ•°æ®ç›®å½•ç»“æ„"""
        if not self.data_root.exists():
            raise FileNotFoundError(f"æ•°æ®æ ¹ç›®å½•ä¸å­˜åœ¨: {self.data_root}")

        if not self.csv_path.exists():
            raise FileNotFoundError(f"csvç›®å½•ä¸å­˜åœ¨: {self.csv_path}")

        print(f"âœ… æ•°æ®ç›®å½•ç»“æ„éªŒè¯é€šè¿‡: {self.data_root}")

    def _get_available_protocols(self) -> List[str]:
        """è·å–å¯ç”¨çš„åè®®åˆ—è¡¨"""
        protocols = []
        for protocol_dir in self.csv_path.iterdir():
            if protocol_dir.is_dir():
                protocols.append(protocol_dir.name.lower())

        print(f"ğŸ“‹ å‘ç°åè®®: {protocols}")
        return sorted(protocols)

    def load_protocol_data(self, protocol_name: str) -> List[Dict]:
        """åŠ è½½æŒ‡å®šåè®®çš„çœŸå®æ•°æ®"""
        protocol_name = protocol_name.lower()

        if protocol_name not in self.supported_protocols:
            print(f"âŒ ä¸æ”¯æŒçš„åè®®: {protocol_name}")
            print(f"   æ”¯æŒçš„åè®®: {self.supported_protocols}")
            return []

        print(f"ğŸ“Š åŠ è½½ {protocol_name.upper()} åè®®çœŸå®æ•°æ®...")

        # ç›´æ¥ä»CSVæ–‡ä»¶åŠ è½½æ•°æ®ï¼ˆæ–°æ ¼å¼ï¼‰
        data = self._load_csv_data_new_format(protocol_name)

        print(f"   âœ… æˆåŠŸåŠ è½½ {len(data)} æ¡çœŸå®æ•°æ®")
        return data

    def _load_csv_data_new_format(self, protocol_name: str) -> List[Dict]:
        """åŠ è½½æ–°æ ¼å¼çš„CSVæ•°æ®ï¼ˆæ¯è¡ŒåŒ…å«HexDataå’ŒBoundariesï¼‰"""
        protocol_csv_path = self.csv_path / protocol_name
        data = []

        if not protocol_csv_path.exists():
            print(f"   âš ï¸  åè®®csvç›®å½•ä¸å­˜åœ¨: {protocol_csv_path}")
            return data

        csv_files = list(protocol_csv_path.glob("*.csv"))
        print(f"   ğŸ“Š æ‰¾åˆ° {len(csv_files)} ä¸ªæ•°æ®æ–‡ä»¶")

        for csv_file in csv_files:
            try:
                # è¯»å–CSVæ–‡ä»¶
                df = pd.read_csv(csv_file)
                print(f"   ğŸ“„ å¤„ç†æ–‡ä»¶: {csv_file.name} ({len(df)} æ¡è®°å½•)")

                # å¤„ç†æ¯ä¸€è¡Œæ•°æ®
                for idx, row in df.iterrows():
                    try:
                        # è·å–HEXæ•°æ®
                        hex_data = str(row.get('HexData', ''))
                        if not hex_data:
                            continue

                        # æ¸…ç†HEXæ•°æ®
                        hex_data = self._clean_hex_data(hex_data)
                        if not hex_data:
                            continue

                        # è½¬æ¢ä¸ºbytes
                        raw_bytes = bytes.fromhex(hex_data)

                        # è·å–è¾¹ç•Œä¿¡æ¯
                        boundaries_str = str(row.get('Boundaries', ''))
                        boundaries = self._parse_boundaries_string(boundaries_str, len(raw_bytes))

                        # åˆ›å»ºæ•°æ®è®°å½•
                        sample = {
                            'file_id': f"{csv_file.stem}_{idx}",
                            'raw_data': hex_data,
                            'protocol': protocol_name,
                            'bytes': raw_bytes,
                            'length': len(raw_bytes),
                            'ground_truth_boundaries': boundaries,
                            'function_code': row.get('FunctionCode', ''),
                            'has_boundary': row.get('HasBoundary', False),
                            'boundary_count': row.get('BoundaryCount', 0),
                            'semantic_type': row.get('SemanticType', ''),
                            'label': row.get('Label', '')
                        }
                        data.append(sample)

                    except Exception as e:
                        print(f"   âš ï¸  å¤„ç†ç¬¬{idx}è¡Œæ•°æ®å¤±è´¥: {e}")
                        continue

            except Exception as e:
                print(f"   âš ï¸  è¯»å–æ–‡ä»¶å¤±è´¥ {csv_file.name}: {e}")
                continue

        return data

    def _parse_boundaries_string(self, boundaries_str: str, max_length: int) -> List[int]:
        """è§£æè¾¹ç•Œå­—ç¬¦ä¸²"""
        boundaries = [0]  # å§‹ç»ˆåŒ…å«èµ·å§‹ä½ç½®

        if not boundaries_str or boundaries_str == 'nan':
            return boundaries

        try:
            # è§£æé€—å·åˆ†éš”çš„è¾¹ç•Œå­—ç¬¦ä¸²
            boundary_parts = boundaries_str.split(',')
            for part in boundary_parts:
                boundary = int(part.strip())
                if 0 <= boundary <= max_length:
                    boundaries.append(boundary)
        except (ValueError, AttributeError) as e:
            print(f"   âš ï¸  è§£æè¾¹ç•Œå­—ç¬¦ä¸²å¤±è´¥: {boundaries_str}, é”™è¯¯: {e}")

        # ç¡®ä¿åŒ…å«ç»“æŸä½ç½®
        if max_length not in boundaries:
            boundaries.append(max_length)

        return sorted(list(set(boundaries)))

    def _clean_hex_data(self, hex_content: str) -> str:
        """æ¸…ç†HEXæ•°æ®"""
        # ç§»é™¤ç©ºæ ¼ã€æ¢è¡Œç¬¦ç­‰
        cleaned = ''.join(hex_content.split())

        # ç§»é™¤éHEXå­—ç¬¦
        cleaned = ''.join(c for c in cleaned if c.lower() in '0123456789abcdef')

        # ç¡®ä¿æ˜¯å¶æ•°é•¿åº¦
        if len(cleaned) % 2 != 0:
            cleaned = cleaned[:-1]  # ç§»é™¤æœ€åä¸€ä¸ªå­—ç¬¦

        return cleaned


class ImprovedFieldHunterAlgorithm:
    """æ”¹è¿›çš„FieldHunterç®—æ³• - å‚è€ƒNetPlieræˆåŠŸç­–ç•¥"""

    def __init__(self, min_field_size: int = 1, max_field_size: int = 64):
        self.min_field_size = min_field_size
        self.max_field_size = max_field_size

        # å‚è€ƒNetPlierçš„å‚æ•°
        self.merge_threshold = 2
        self.confidence_threshold = 0.6  # æé«˜ç½®ä¿¡åº¦é˜ˆå€¼
        self.boundary_tolerance = 1

        # åè®®ç‰¹å¼‚æ€§å‚æ•°
        self.protocol_params = {
            'dns': {'min_field_size': 2, 'merge_threshold': 1},
            'modbus': {'min_field_size': 1, 'merge_threshold': 2},
            'smb': {'min_field_size': 1, 'merge_threshold': 4},
            'dhcp': {'min_field_size': 1, 'merge_threshold': 3}
        }

    def extract_fields(self, packet_data: List[bytes], protocol_name: str = None) -> List[List[int]]:
        """ä»æ•°æ®åŒ…åˆ—è¡¨ä¸­æå–å­—æ®µè¾¹ç•Œ - æ”¹è¿›ç‰ˆ"""
        if not packet_data:
            return []

        print(f"ğŸ” æ”¹è¿›ç‰ˆFieldHunteråˆ†æ {len(packet_data)} ä¸ªæ•°æ®åŒ…...")

        # åº”ç”¨åè®®ç‰¹å¼‚æ€§å‚æ•°
        if protocol_name and protocol_name in self.protocol_params:
            params = self.protocol_params[protocol_name]
            self.min_field_size = params.get('min_field_size', self.min_field_size)
            self.merge_threshold = params.get('merge_threshold', self.merge_threshold)

        # ç»Ÿä¸€åŒ…é•¿åº¦åˆ†æ
        lengths = [len(packet) for packet in packet_data]
        common_length = self._find_common_length(lengths)

        if common_length:
            print(f"   æ£€æµ‹åˆ°å¸¸è§åŒ…é•¿åº¦: {common_length}")
            same_length_packets = [p for p in packet_data if len(p) == common_length]
            if len(same_length_packets) >= max(10, len(packet_data) * 0.3):
                return self._analyze_fixed_length_packets_improved(same_length_packets, packet_data, protocol_name)

        # å˜é•¿åŒ…åˆ†æ
        return self._analyze_variable_length_packets_improved(packet_data, protocol_name)

    def _find_common_length(self, lengths: List[int]) -> Optional[int]:
        """æ‰¾åˆ°æœ€å¸¸è§çš„åŒ…é•¿åº¦"""
        length_counts = Counter(lengths)
        if not length_counts:
            return None

        most_common_length, count = length_counts.most_common(1)[0]
        if count >= max(10, len(lengths) * 0.3):
            return most_common_length

        return None

    def _analyze_fixed_length_packets_improved(self, same_length_packets: List[bytes],
                                               all_packets: List[bytes],
                                               protocol_name: str) -> List[List[int]]:
        """æ”¹è¿›çš„å›ºå®šé•¿åº¦æ•°æ®åŒ…åˆ†æ"""
        if not same_length_packets:
            return [[] for _ in all_packets]

        packet_length = len(same_length_packets[0])
        print(f"   åˆ†æå›ºå®šé•¿åº¦åŒ… (é•¿åº¦={packet_length})")

        # 1. æ£€æµ‹é«˜è´¨é‡è¾¹ç•Œå€™é€‰ - å¢å¼ºç‰ˆ
        high_quality_candidates = self._detect_comprehensive_boundaries(same_length_packets, protocol_name)

        # 2. æ™ºèƒ½è¾¹ç•Œé€‰æ‹© - æ›´å®½æ¾çš„ç­–ç•¥
        selected_boundaries = self._enhanced_boundary_selection(high_quality_candidates, packet_length)

        # 3. NetPlieré£æ ¼åå¤„ç† - å‡å°‘è¿‡åº¦åˆå¹¶
        final_boundaries = self._flexible_postprocessing(selected_boundaries, packet_length, protocol_name)

        print(f"   æ£€æµ‹åˆ°è¾¹ç•Œ: {final_boundaries}")

        # ä¸ºæ‰€æœ‰åŒ…åº”ç”¨è¾¹ç•Œæ¨¡å¼
        result = []
        for packet in all_packets:
            if len(packet) == packet_length:
                result.append(final_boundaries)
            else:
                adjusted_boundaries = self._adjust_boundaries_for_length(
                    final_boundaries, len(packet), packet_length
                )
                result.append(adjusted_boundaries)

        return result

    def _detect_comprehensive_boundaries(self, packets: List[bytes], protocol_name: str) -> List[int]:
        """æ£€æµ‹å…¨é¢çš„è¾¹ç•Œå€™é€‰ - å¢å¼ºç‰ˆ"""
        print("   æ£€æµ‹å…¨é¢è¾¹ç•Œå€™é€‰...")

        if not packets:
            return [0]

        packet_length = len(packets[0])
        candidates = [0]  # å§‹ç»ˆåŒ…å«èµ·å§‹ä½ç½®

        # 1. åŸºäºç†µå˜åŒ–çš„è¾¹ç•Œæ£€æµ‹
        entropy_boundaries = self._detect_entropy_change_boundaries(packets)
        candidates.extend(entropy_boundaries)

        # 2. åŸºäºå­—èŠ‚å€¼åˆ†å¸ƒå˜åŒ–çš„è¾¹ç•Œæ£€æµ‹
        distribution_boundaries = self._detect_distribution_change_boundaries(packets)
        candidates.extend(distribution_boundaries)

        # 3. åŸºäºç›¸å…³æ€§å˜åŒ–çš„è¾¹ç•Œæ£€æµ‹
        correlation_boundaries = self._detect_correlation_boundaries(packets)
        candidates.extend(correlation_boundaries)

        # 4. åè®®ç‰¹å¼‚æ€§è¾¹ç•Œ
        if protocol_name:
            protocol_boundaries = self._detect_protocol_specific_boundaries(packets, protocol_name)
            candidates.extend(protocol_boundaries)

        # 5. å¯¹é½è¾¹ç•Œ
        alignment_boundaries = self._detect_alignment_boundaries(packet_length)
        candidates.extend(alignment_boundaries)

        # å»é‡å¹¶æ’åº
        candidates = sorted(list(set(candidates)))

        # è¿‡æ»¤ä½è´¨é‡è¾¹ç•Œ - ä½¿ç”¨æ›´å®½æ¾çš„é˜ˆå€¼
        quality_candidates = self._filter_quality_boundaries_relaxed(candidates, packets)

        print(f"   æ£€æµ‹åˆ° {len(quality_candidates)} ä¸ªè¾¹ç•Œå€™é€‰")
        return quality_candidates

    def _detect_entropy_change_boundaries(self, packets: List[bytes]) -> List[int]:
        """åŸºäºç†µå˜åŒ–çš„è¾¹ç•Œæ£€æµ‹"""
        boundaries = []
        if not packets:
            return boundaries

        packet_length = len(packets[0])

        # è®¡ç®—æ¯ä¸ªä½ç½®çš„ç†µ
        entropies = []
        for pos in range(packet_length):
            values = [packet[pos] for packet in packets if pos < len(packet)]
            if values:
                entropy = self._calculate_entropy(values)
                entropies.append(entropy)
            else:
                entropies.append(0)

        # å¯»æ‰¾ç†µçš„æ˜¾è‘—å˜åŒ–ç‚¹
        for i in range(1, len(entropies) - 1):
            left_entropy = entropies[i - 1]
            curr_entropy = entropies[i]
            right_entropy = entropies[i + 1]

            # å¦‚æœå½“å‰ä½ç½®çš„ç†µä¸é‚»è¿‘ä½ç½®æœ‰æ˜¾è‘—å·®å¼‚
            if abs(curr_entropy - left_entropy) > 0.3 or abs(curr_entropy - right_entropy) > 0.3:
                boundaries.append(i)

        return boundaries

    def _detect_distribution_change_boundaries(self, packets: List[bytes]) -> List[int]:
        """åŸºäºå­—èŠ‚å€¼åˆ†å¸ƒå˜åŒ–çš„è¾¹ç•Œæ£€æµ‹"""
        boundaries = []
        if not packets:
            return boundaries

        packet_length = len(packets[0])

        # ä½¿ç”¨æ»‘åŠ¨çª—å£æ£€æµ‹åˆ†å¸ƒå˜åŒ–
        window_size = 3
        for pos in range(window_size, packet_length - window_size):
            # è·å–çª—å£å†…çš„å­—èŠ‚å€¼åˆ†å¸ƒ
            left_values = []
            right_values = []

            for packet in packets:
                if pos < len(packet):
                    # å·¦çª—å£
                    for i in range(max(0, pos - window_size), pos):
                        if i < len(packet):
                            left_values.append(packet[i])
                    # å³çª—å£
                    for i in range(pos, min(len(packet), pos + window_size)):
                        right_values.append(packet[i])

            if left_values and right_values:
                # è®¡ç®—åˆ†å¸ƒçš„å·®å¼‚
                left_dist = self._calculate_distribution_stats(left_values)
                right_dist = self._calculate_distribution_stats(right_values)

                # å¦‚æœåˆ†å¸ƒæœ‰æ˜¾è‘—å·®å¼‚ï¼Œè®¤ä¸ºæ˜¯è¾¹ç•Œ
                if self._distributions_differ(left_dist, right_dist):
                    boundaries.append(pos)

        return boundaries

    def _detect_correlation_boundaries(self, packets: List[bytes]) -> List[int]:
        """åŸºäºç›¸å…³æ€§å˜åŒ–çš„è¾¹ç•Œæ£€æµ‹"""
        boundaries = []
        if not packets or len(packets[0]) < 4:
            return boundaries

        packet_length = len(packets[0])

        # è®¡ç®—ç›¸é‚»å­—èŠ‚çš„ç›¸å…³æ€§
        for pos in range(1, packet_length - 1):
            correlations = []

            for i in range(len(packets)):
                if pos + 1 < len(packets[i]):
                    # è®¡ç®—å½“å‰ä½ç½®ä¸ä¸‹ä¸€ä½ç½®çš„ç›¸å…³æ€§
                    curr_byte = packets[i][pos]
                    next_byte = packets[i][pos + 1]
                    correlations.append(abs(curr_byte - next_byte))

            if correlations:
                avg_correlation = np.mean(correlations)
                std_correlation = np.std(correlations)

                # å¦‚æœç›¸å…³æ€§å˜åŒ–å¾ˆå¤§ï¼Œå¯èƒ½æ˜¯è¾¹ç•Œ
                if std_correlation > 30:  # è°ƒæ•´é˜ˆå€¼
                    boundaries.append(pos + 1)

        return boundaries

    def _detect_protocol_specific_boundaries(self, packets: List[bytes], protocol_name: str) -> List[int]:
        """æ£€æµ‹åè®®ç‰¹å¼‚æ€§è¾¹ç•Œ"""
        boundaries = []
        if not packets:
            return boundaries

        packet_length = len(packets[0])

        if protocol_name == 'dns':
            # DNSåè®®çš„å›ºå®šå¤´éƒ¨æ˜¯12å­—èŠ‚
            if packet_length >= 12:
                boundaries.extend([2, 4, 6, 8, 10, 12])
        elif protocol_name == 'modbus':
            # Modbusåè®®çš„MBAPå¤´éƒ¨æ˜¯7å­—èŠ‚
            if packet_length >= 7:
                boundaries.extend([2, 4, 6, 7])
            # æ·»åŠ PDUç›¸å…³è¾¹ç•Œ
            if packet_length >= 9:
                boundaries.extend([8, 9])
        elif protocol_name in ['smb', 'smb2']:
            # SMBåè®®çš„å¤´éƒ¨å­—æ®µ
            if packet_length >= 8:
                boundaries.extend([4, 8])
            if packet_length >= 16:
                boundaries.extend([12, 16])
        elif protocol_name == 'dhcp':
            # DHCPåè®®çš„å¸¸è§å­—æ®µè¾¹ç•Œ
            if packet_length >= 28:
                boundaries.extend([1, 2, 3, 4, 8, 12, 16, 20, 24, 28])

        return [b for b in boundaries if b < packet_length]

    def _detect_alignment_boundaries(self, packet_length: int) -> List[int]:
        """æ£€æµ‹å¯¹é½è¾¹ç•Œ"""
        boundaries = []

        # 1å­—èŠ‚å¯¹é½ - æ¯ä¸ªä½ç½®éƒ½å¯èƒ½æ˜¯è¾¹ç•Œ
        for pos in range(1, packet_length):
            boundaries.append(pos)

        return boundaries

    def _calculate_entropy(self, values: List[int]) -> float:
        """è®¡ç®—ç†µ"""
        if not values:
            return 0.0

        counts = Counter(values)
        total = len(values)
        entropy = 0.0

        for count in counts.values():
            if count > 0:
                p = count / total
                entropy -= p * math.log2(p)

        return entropy

    def _calculate_distribution_stats(self, values: List[int]) -> Dict:
        """è®¡ç®—åˆ†å¸ƒç»Ÿè®¡"""
        if not values:
            return {'mean': 0, 'std': 0, 'min': 0, 'max': 0}

        return {
            'mean': np.mean(values),
            'std': np.std(values),
            'min': np.min(values),
            'max': np.max(values)
        }

    def _distributions_differ(self, dist1: Dict, dist2: Dict) -> bool:
        """åˆ¤æ–­ä¸¤ä¸ªåˆ†å¸ƒæ˜¯å¦æœ‰æ˜¾è‘—å·®å¼‚"""
        mean_diff = abs(dist1['mean'] - dist2['mean'])
        std_diff = abs(dist1['std'] - dist2['std'])

        return mean_diff > 20 or std_diff > 15

    def _filter_quality_boundaries_relaxed(self, candidates: List[int], packets: List[bytes]) -> List[int]:
        """è¿‡æ»¤ä½è´¨é‡è¾¹ç•Œ - æ›´å®½æ¾çš„ç­–ç•¥"""
        if not candidates or not packets:
            return candidates

        # é™ä½è´¨é‡é˜ˆå€¼ï¼Œä¿ç•™æ›´å¤šè¾¹ç•Œ
        quality_threshold = 0.1  # ä»0.4é™ä½åˆ°0.1
        quality_candidates = []

        for candidate in candidates:
            # è®¡ç®—è¯¥ä½ç½®çš„è´¨é‡åˆ†æ•°
            quality_score = self._calculate_boundary_quality_score(candidate, packets)

            # ä¿ç•™è´¨é‡åˆ†æ•°è¾ƒé«˜çš„è¾¹ç•Œ
            if quality_score > quality_threshold:
                quality_candidates.append(candidate)

        return quality_candidates

    def _calculate_boundary_quality_score(self, position: int, packets: List[bytes]) -> float:
        """è®¡ç®—è¾¹ç•Œè´¨é‡åˆ†æ•°"""
        if not packets or position >= len(packets[0]):
            return 0.0

        score = 0.1  # åŸºç¡€åˆ†æ•°

        # 1. ä½ç½®åˆ†æ•°ï¼ˆæ‰€æœ‰ä½ç½®éƒ½æœ‰åŸºæœ¬åˆ†æ•°ï¼‰
        score += 0.2

        # 2. å¯¹é½åˆ†æ•°
        if position % 4 == 0:
            score += 0.3
        elif position % 2 == 0:
            score += 0.2

        # 3. ç»Ÿè®¡å˜åŒ–åˆ†æ•°
        if position > 0 and position < len(packets[0]):
            left_values = [packet[position - 1] for packet in packets if position - 1 < len(packet)]
            right_values = [packet[position] for packet in packets if position < len(packet)]

            if left_values and right_values:
                left_entropy = self._calculate_entropy(left_values)
                right_entropy = self._calculate_entropy(right_values)

                entropy_diff = abs(right_entropy - left_entropy)
                if entropy_diff > 0.1:  # é™ä½é˜ˆå€¼
                    score += 0.2

        return min(1.0, score)

    def _enhanced_boundary_selection(self, candidates: List[int], packet_length: int) -> List[int]:
        """å¢å¼ºçš„è¾¹ç•Œé€‰æ‹© - æ›´å®½æ¾çš„ç­–ç•¥"""
        print("   å¢å¼ºè¾¹ç•Œé€‰æ‹©...")

        if not candidates:
            return [0]

        # æŒ‰é‡è¦æ€§æ’åºå€™é€‰è¾¹ç•Œ
        scored_candidates = []
        for candidate in candidates:
            score = self._calculate_boundary_importance_relaxed(candidate, packet_length)
            scored_candidates.append((candidate, score))

        # æŒ‰åˆ†æ•°æ’åº
        scored_candidates.sort(key=lambda x: x[1], reverse=True)

        # é€‰æ‹©æ›´å¤šçš„é«˜åˆ†è¾¹ç•Œ
        selected = [0]  # å§‹ç»ˆåŒ…å«èµ·å§‹ä½ç½®
        for candidate, score in scored_candidates:
            if score > 0.2 and candidate not in selected:  # é™ä½é˜ˆå€¼ä»0.5åˆ°0.2
                selected.append(candidate)
                # å¢åŠ è¾¹ç•Œæ•°é‡é™åˆ¶ï¼Œå…è®¸æ›´å¤šåˆ†å‰²
                if len(selected) >= min(16, packet_length // 2):  # ä»8å¢åŠ åˆ°16
                    break

        return sorted(selected)

    def _calculate_boundary_importance_relaxed(self, position: int, packet_length: int) -> float:
        """è®¡ç®—è¾¹ç•Œé‡è¦æ€§ - æ›´å®½æ¾çš„ç­–ç•¥"""
        if position >= packet_length:
            return 0.0

        importance = 0.1  # åŸºç¡€é‡è¦æ€§

        # 1. ä½ç½®é‡è¦æ€§ - æ‰€æœ‰ä½ç½®éƒ½æœ‰ä¸€å®šé‡è¦æ€§
        if position < packet_length // 2:  # å‰åŠéƒ¨åˆ†
            importance += 0.3
        else:
            importance += 0.2

        # 2. å¯¹é½é‡è¦æ€§
        if position % 4 == 0:
            importance += 0.3
        elif position % 2 == 0:
            importance += 0.2
        else:
            importance += 0.1

        # 3. ç›¸å¯¹ä½ç½®é‡è¦æ€§
        relative_pos = position / packet_length
        if relative_pos < 0.8:  # å¤§éƒ¨åˆ†ä½ç½®éƒ½é‡è¦
            importance += 0.2

        return min(1.0, importance)

    def _flexible_postprocessing(self, boundaries: List[int], packet_length: int, protocol_name: str) -> List[int]:
        """çµæ´»çš„åå¤„ç† - å‡å°‘è¿‡åº¦åˆå¹¶"""
        print("   çµæ´»åå¤„ç†...")

        # 1. è½»å¾®åˆå¹¶è¿‡å°çš„å­—æ®µ
        merged = self._merge_small_fields_flexible(boundaries)

        # 2. è¾¹ç•Œå¯¹é½
        aligned = self._align_boundaries_flexible(merged, packet_length)

        # 3. åº”ç”¨åè®®è§„åˆ™
        if protocol_name:
            aligned = self._apply_protocol_rules(aligned, protocol_name, packet_length)

        # 4. éªŒè¯å’Œæ¸…ç†
        final = self._validate_and_clean_boundaries_flexible(aligned, packet_length)

        return final

    def _merge_small_fields_flexible(self, boundaries: List[int]) -> List[int]:
        """çµæ´»åˆå¹¶è¿‡å°çš„å­—æ®µ"""
        if len(boundaries) <= 2:
            return boundaries

        merged = [boundaries[0]]

        for i in range(1, len(boundaries)):
            field_size = boundaries[i] - merged[-1]

            # åªåˆå¹¶éå¸¸å°çš„å­—æ®µï¼ˆ1å­—èŠ‚ï¼‰ï¼Œä¿ç•™æ›´å¤šè¾¹ç•Œ
            if field_size < 1:  # å‡å°‘åˆå¹¶é˜ˆå€¼
                continue  # è·³è¿‡è¿™ä¸ªè¾¹ç•Œï¼Œå®ç°åˆå¹¶
            else:
                merged.append(boundaries[i])

        return merged

    def _align_boundaries_flexible(self, boundaries: List[int], packet_length: int) -> List[int]:
        """çµæ´»è¾¹ç•Œå¯¹é½"""
        aligned = [boundaries[0]]

        for boundary in boundaries[1:]:
            # ä¿æŒåŸå§‹è¾¹ç•Œï¼Œå‡å°‘å¯¹é½è°ƒæ•´
            aligned_boundary = boundary

            # ç¡®ä¿ä¸ä¸å‰ä¸€ä¸ªè¾¹ç•Œé‡å¤
            if aligned_boundary > aligned[-1]:
                aligned.append(aligned_boundary)

        return aligned

    def _apply_protocol_rules(self, boundaries: List[int], protocol_name: str, packet_length: int) -> List[int]:
        """åº”ç”¨åè®®è§„åˆ™"""
        if protocol_name == 'dns':
            # DNSåè®®ï¼šç¡®ä¿å¤´éƒ¨12å­—èŠ‚å®Œæ•´
            if 12 not in boundaries and 12 < packet_length:
                boundaries = sorted(boundaries + [12])
        elif protocol_name == 'modbus':
            # Modbusåè®®ï¼šç¡®ä¿MBAPå¤´éƒ¨7å­—èŠ‚
            if 7 not in boundaries and 7 < packet_length:
                boundaries = sorted(boundaries + [7])
        elif protocol_name in ['smb', 'smb2']:
            # SMBåè®®ï¼šç¡®ä¿å¤´éƒ¨å­—æ®µ
            important_positions = [4, 8]
            for pos in important_positions:
                if pos not in boundaries and pos < packet_length:
                    boundaries = sorted(boundaries + [pos])

        return boundaries

    def _validate_and_clean_boundaries_flexible(self, boundaries: List[int], packet_length: int) -> List[int]:
        """çµæ´»éªŒè¯å’Œæ¸…ç†è¾¹ç•Œ"""
        # ç¡®ä¿è¾¹ç•Œåœ¨æœ‰æ•ˆèŒƒå›´å†…
        valid_boundaries = [b for b in boundaries if 0 <= b < packet_length]

        # ç¡®ä¿åŒ…å«èµ·å§‹ä½ç½®
        if 0 not in valid_boundaries:
            valid_boundaries.insert(0, 0)

        # ç§»é™¤é‡å¤è¾¹ç•Œ
        valid_boundaries = sorted(list(set(valid_boundaries)))

        # å¢åŠ å­—æ®µæ•°é‡é™åˆ¶ï¼Œå…è®¸æ›´ç²¾ç»†çš„åˆ†å‰²
        max_fields = min(32, packet_length)  # å¤§å¹…å¢åŠ é™åˆ¶
        if len(valid_boundaries) > max_fields:
            valid_boundaries = valid_boundaries[:max_fields]

        return valid_boundaries

    def _analyze_variable_length_packets_improved(self, packet_data: List[bytes], protocol_name: str) -> List[
        List[int]]:
        """æ”¹è¿›çš„å˜é•¿æ•°æ®åŒ…åˆ†æ"""
        print(f"   åˆ†æå˜é•¿æ•°æ®åŒ…")

        result = []

        # æŒ‰é•¿åº¦åˆ†ç»„åˆ†æ
        length_groups = defaultdict(list)
        for i, packet in enumerate(packet_data):
            length_groups[len(packet)].append((i, packet))

        # ä¸ºæ¯ä¸ªé•¿åº¦ç»„æ‰¾åˆ°è¾¹ç•Œæ¨¡å¼
        length_patterns = {}
        for length, packets in length_groups.items():
            if len(packets) >= 3:  # é™ä½æœ€å°æ ·æœ¬è¦æ±‚
                packet_bytes = [p[1] for p in packets]
                boundaries = self._find_boundaries_for_length_group_improved(packet_bytes, protocol_name)
                length_patterns[length] = boundaries

        # ä¸ºæ¯ä¸ªåŒ…åˆ†é…è¾¹ç•Œ
        for i, packet in enumerate(packet_data):
            length = len(packet)
            if length in length_patterns:
                result.append(length_patterns[length])
            else:
                # ä½¿ç”¨æ”¹è¿›çš„å¯å‘å¼æ–¹æ³•
                boundaries = self._improved_heuristic_boundaries(packet, protocol_name)
                result.append(boundaries)

        return result

    def _find_boundaries_for_length_group_improved(self, packets: List[bytes], protocol_name: str) -> List[int]:
        """ä¸ºç‰¹å®šé•¿åº¦ç»„æ‰¾åˆ°æ”¹è¿›çš„è¾¹ç•Œ"""
        if not packets:
            return [0]

        # ä½¿ç”¨æ”¹è¿›çš„åˆ†ææ–¹æ³•
        high_quality_candidates = self._detect_comprehensive_boundaries(packets, protocol_name)
        selected_boundaries = self._enhanced_boundary_selection(high_quality_candidates, len(packets[0]))
        final_boundaries = self._flexible_postprocessing(selected_boundaries, len(packets[0]), protocol_name)

        return final_boundaries

    def _improved_heuristic_boundaries(self, packet: bytes, protocol_name: str) -> List[int]:
        """æ”¹è¿›çš„å¯å‘å¼è¾¹ç•Œæ–¹æ³•"""
        length = len(packet)
        boundaries = [0]

        # åè®®ç‰¹å¼‚æ€§å¯å‘å¼
        if protocol_name == 'dns' and length >= 12:
            boundaries.extend([2, 4, 6, 8, 10, 12])
        elif protocol_name == 'modbus' and length >= 7:
            boundaries.extend([2, 4, 6, 7])
        elif protocol_name in ['smb', 'smb2'] and length >= 8:
            boundaries.extend([4, 8])
        else:
            # é€šç”¨å¯å‘å¼ - æ›´ç»†ç²’åº¦çš„åˆ†å‰²
            if length <= 8:
                for i in range(1, length):
                    boundaries.append(i)
            elif length <= 16:
                for i in range(1, length, 1):  # æ¯ä¸ªå­—èŠ‚éƒ½æ˜¯æ½œåœ¨è¾¹ç•Œ
                    boundaries.append(i)
            elif length <= 32:
                for i in range(2, length, 2):
                    boundaries.append(i)
            else:
                # é•¿åŒ…ï¼šå¤šå±‚æ¬¡åˆ†æ
                for i in range(4, length, 4):
                    boundaries.append(i)

        # è¿‡æ»¤æœ‰æ•ˆè¾¹ç•Œ
        valid_boundaries = [b for b in boundaries if 0 <= b < length]

        # åº”ç”¨åå¤„ç†
        final_boundaries = self._flexible_postprocessing(valid_boundaries, length, protocol_name)

        return final_boundaries

    def _adjust_boundaries_for_length(self, base_boundaries: List[int], target_length: int, base_length: int) -> List[
        int]:
        """ä¸ºä¸åŒé•¿åº¦çš„åŒ…è°ƒæ•´è¾¹ç•Œ"""
        if target_length == base_length:
            return base_boundaries

        # æ™ºèƒ½æ¯”ä¾‹è°ƒæ•´
        ratio = target_length / base_length
        adjusted = []

        for boundary in base_boundaries:
            new_boundary = int(boundary * ratio)

            # ç¡®ä¿è¾¹ç•Œåœ¨æœ‰æ•ˆèŒƒå›´å†…
            if 0 <= new_boundary < target_length:
                adjusted.append(new_boundary)

        # ç¡®ä¿åŒ…å«èµ·å§‹ä½ç½®
        if 0 not in adjusted:
            adjusted.insert(0, 0)

        return sorted(list(set(adjusted)))


class ImprovedFieldHunterEvaluator:
    """æ”¹è¿›çš„FieldHunterè¯„ä¼°å™¨ - å¢åŠ è°ƒè¯•ä¿¡æ¯"""

    def __init__(self):
        self.boundary_tolerance = 1
        self.debug_mode = True

    def evaluate_boundaries(self, predicted_boundaries: List[int],
                            ground_truth_boundaries: List[int],
                            sequence_length: int,
                            sample_id: str = None) -> Dict[str, float]:
        """è¯„ä¼°è¾¹ç•Œæ£€æµ‹æ€§èƒ½ - å¢åŠ è°ƒè¯•ä¿¡æ¯"""
        if self.debug_mode and sample_id and sample_id.endswith('_0'):  # åªå¯¹ç¬¬ä¸€ä¸ªæ ·æœ¬è¾“å‡ºè¯¦ç»†ä¿¡æ¯
            print(f"\n   ğŸ“‹ è°ƒè¯•ä¿¡æ¯ (æ ·æœ¬ {sample_id}):")
            print(f"      åºåˆ—é•¿åº¦: {sequence_length}")
            print(f"      çœŸå®è¾¹ç•Œ: {ground_truth_boundaries}")
            print(f"      é¢„æµ‹è¾¹ç•Œ: {predicted_boundaries}")

            # è½¬æ¢ä¸ºå­—æ®µ
            true_fields = self._boundaries_to_fields(ground_truth_boundaries, sequence_length)
            pred_fields = self._boundaries_to_fields(predicted_boundaries, sequence_length)
            print(f"      çœŸå®å­—æ®µ: {true_fields}")
            print(f"      é¢„æµ‹å­—æ®µ: {pred_fields}")
            print(f"      çœŸå®å­—æ®µæ•°é‡: {len(true_fields)}")
            print(f"      é¢„æµ‹å­—æ®µæ•°é‡: {len(pred_fields)}")

        standard_metrics = self._standard_evaluation(predicted_boundaries, ground_truth_boundaries, sequence_length)

        return standard_metrics

    def _standard_evaluation(self, predicted_boundaries: List[int],
                             ground_truth_boundaries: List[int],
                             sequence_length: int) -> Dict[str, float]:
        """æ ‡å‡†è¯„ä¼°"""
        pred_labels = np.zeros(sequence_length, dtype=int)
        true_labels = np.zeros(sequence_length, dtype=int)

        for boundary in predicted_boundaries:
            if 0 <= boundary < sequence_length:
                pred_labels[boundary] = 1

        for boundary in ground_truth_boundaries:
            if 0 <= boundary < sequence_length:
                true_labels[boundary] = 1

        accuracy = accuracy_score(true_labels, pred_labels)
        f1 = f1_score(true_labels, pred_labels, zero_division=0)

        tp = np.sum((pred_labels == 1) & (true_labels == 1))
        fp = np.sum((pred_labels == 1) & (true_labels == 0))
        fn = np.sum((pred_labels == 0) & (true_labels == 1))

        precision = tp / (tp + fp) if (tp + fp) > 0 else 0
        recall = tp / (tp + fn) if (tp + fn) > 0 else 0

        pred_fields = self._boundaries_to_fields(predicted_boundaries, sequence_length)
        true_fields = self._boundaries_to_fields(ground_truth_boundaries, sequence_length)

        if len(true_fields) > 0:
            perfect_matches = len(set(pred_fields) & set(true_fields))
            perfection = perfect_matches / len(true_fields)
        else:
            perfection = 0

        return {
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1_score': f1,
            'perfection': perfection
        }

    def _boundaries_to_fields(self, boundaries: List[int], length: int) -> List[Tuple[int, int]]:
        """å°†è¾¹ç•Œè½¬æ¢ä¸ºå­—æ®µ"""
        if not boundaries:
            return [(0, length)] if length > 0 else []

        fields = []
        boundaries = sorted(set(boundaries))

        for i in range(len(boundaries)):
            start = boundaries[i]
            if i < len(boundaries) - 1:
                end = boundaries[i + 1]
            else:
                end = length

            if start < end and start < length:
                fields.append((start, min(end, length)))

        return fields


class RealDataFieldHunterExperiment:
    """ä½¿ç”¨çœŸå®æ•°æ®é›†çš„FieldHunterå®éªŒç®¡ç†å™¨"""

    def __init__(self, data_root: str = "../../Msg2"):
        try:
            self.data_loader = RealDataFieldHunterDataLoader(data_root)
            self.algorithm = ImprovedFieldHunterAlgorithm()
            self.evaluator = ImprovedFieldHunterEvaluator()
            self.data_root = data_root

            # è·å–æ”¯æŒçš„åè®®åˆ—è¡¨
            self.protocols = self.data_loader.supported_protocols

            if not self.protocols:
                print("âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ”¯æŒçš„åè®®æ•°æ®")

        except Exception as e:
            print(f"âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
            raise

        self.results = {}

    def run_experiments(self, protocols: List[str] = None, max_samples: int = None):
        """è¿è¡Œå®éªŒ"""
        if protocols is None:
            protocols = self.protocols

        print("ğŸš€ FieldHunterçœŸå®æ•°æ®å®éªŒå¼€å§‹")
        print("=" * 70)

        for protocol in protocols:
            if protocol not in self.protocols:
                print(f"âŒ è·³è¿‡ä¸æ”¯æŒçš„åè®®: {protocol}")
                continue

            print(f"\nğŸ“Š æµ‹è¯•åè®®: {protocol.upper()}")
            print("-" * 50)

            try:
                data = self.data_loader.load_protocol_data(protocol)

                if not data:
                    print(f"   âŒ è·³è¿‡ {protocol}: æ— æ•°æ®")
                    continue

                # å¦‚æœæ²¡æœ‰æŒ‡å®šæœ€å¤§æ ·æœ¬æ•°ï¼Œåˆ™ä½¿ç”¨è¯¥åè®®çš„æ‰€æœ‰æ•°æ®
                if max_samples is None:
                    protocol_max_samples = len(data)
                else:
                    protocol_max_samples = max_samples

                if len(data) > protocol_max_samples:
                    data = random.sample(data, protocol_max_samples)
                    print(f"   ğŸ“ é™åˆ¶æ ·æœ¬æ•°é‡: {protocol_max_samples}")

                # åˆ†æçœŸå®è¾¹ç•Œç»Ÿè®¡
                self._analyze_ground_truth_statistics(data, protocol)

                packet_data = [sample['bytes'] for sample in data]

                print(f"   ğŸ” è¿è¡Œæ”¹è¿›ç‰ˆFieldHunterç®—æ³•...")
                predicted_boundaries = self.algorithm.extract_fields(packet_data, protocol)

                print(f"   ğŸ“ˆ è¯„ä¼°æ€§èƒ½...")
                all_metrics = []

                for sample, pred_boundaries in zip(data, predicted_boundaries):
                    true_boundaries = sample['ground_truth_boundaries']
                    length = sample['length']
                    sample_id = sample['file_id']

                    metrics = self.evaluator.evaluate_boundaries(pred_boundaries, true_boundaries, length, sample_id)
                    all_metrics.append(metrics)

                if all_metrics:
                    avg_metrics = {}
                    for key in ['accuracy', 'precision', 'recall', 'f1_score', 'perfection']:
                        values = [m[key] for m in all_metrics if not np.isnan(m[key])]
                        avg_metrics[key] = np.mean(values) if values else 0.0

                    self.results[protocol] = {
                        'sample_count': len(data),
                        'metrics': avg_metrics
                    }

                    print(f"   âœ… ç»“æœ:")
                    print(f"      æ ·æœ¬æ•°é‡: {len(data)}")
                    print(f"      å‡†ç¡®ç‡: {avg_metrics['accuracy']:.4f}")
                    print(f"      ç²¾ç¡®ç‡: {avg_metrics['precision']:.4f}")
                    print(f"      å¬å›ç‡: {avg_metrics['recall']:.4f}")
                    print(f"      F1åˆ†æ•°: {avg_metrics['f1_score']:.4f}")
                    print(f"      å®Œç¾ç‡: {avg_metrics['perfection']:.4f}")
                else:
                    print(f"   âš ï¸  è¯„ä¼°æŒ‡æ ‡è®¡ç®—å¤±è´¥")

            except Exception as e:
                print(f"   âŒ å¤„ç† {protocol} æ—¶å‡ºé”™: {e}")
                self.results[protocol] = {
                    'sample_count': 0,
                    'metrics': {'accuracy': 0, 'precision': 0, 'recall': 0,
                                'f1_score': 0, 'perfection': 0},
                    'error': str(e)
                }

    def _analyze_ground_truth_statistics(self, data: List[Dict], protocol: str):
        """åˆ†æçœŸå®è¾¹ç•Œç»Ÿè®¡ä¿¡æ¯"""
        print(f"   ğŸ“Š åˆ†æ {protocol.upper()} åè®®çœŸå®è¾¹ç•Œç»Ÿè®¡:")

        boundary_counts = [len(sample['ground_truth_boundaries']) for sample in data]
        field_counts = [len(sample['ground_truth_boundaries']) - 1 for sample in data if
                        len(sample['ground_truth_boundaries']) > 1]
        packet_lengths = [sample['length'] for sample in data]

        print(f"      æ•°æ®åŒ…é•¿åº¦èŒƒå›´: {min(packet_lengths)} - {max(packet_lengths)}")
        print(f"      å¹³å‡æ•°æ®åŒ…é•¿åº¦: {np.mean(packet_lengths):.1f}")
        print(f"      å¹³å‡è¾¹ç•Œæ•°é‡: {np.mean(boundary_counts):.1f}")
        print(f"      å¹³å‡å­—æ®µæ•°é‡: {np.mean(field_counts):.1f}" if field_counts else "      å¹³å‡å­—æ®µæ•°é‡: 0")

        # æ˜¾ç¤ºä¸€äº›ç¤ºä¾‹
        print(f"      è¾¹ç•Œç¤ºä¾‹ (å‰3ä¸ªæ ·æœ¬):")
        for i, sample in enumerate(data[:3]):
            print(f"        æ ·æœ¬{i + 1}: é•¿åº¦={sample['length']}, è¾¹ç•Œ={sample['ground_truth_boundaries']}")

    def generate_report(self):
        """ç”ŸæˆæŠ¥å‘Š"""
        print(f"\n" + "=" * 70)
        print("ğŸ“Š FieldHunterçœŸå®æ•°æ®å®éªŒæŠ¥å‘Š")
        print("=" * 70)

        if not self.results:
            print("âŒ æ²¡æœ‰å®éªŒç»“æœ")
            return

        report_data = []
        for protocol, result in self.results.items():
            metrics = result['metrics']
            report_data.append({
                'Protocol': protocol.upper(),
                'Samples': result['sample_count'],
                'Accuracy': f"{metrics['accuracy']:.4f}",
                'Precision': f"{metrics['precision']:.4f}",
                'Recall': f"{metrics['recall']:.4f}",
                'F1-score': f"{metrics['f1_score']:.4f}",
                'Perfection': f"{metrics['perfection']:.4f}"
            })

        df = pd.DataFrame(report_data)
        print("\nFieldHunterçœŸå®æ•°æ®å®éªŒç»“æœè¡¨æ ¼:")
        print(df.to_string(index=False))

        # è®¡ç®—å¹³å‡æ€§èƒ½
        valid_results = [r for r in self.results.values() if r['sample_count'] > 0]
        if valid_results:
            avg_perfection = np.mean([r['metrics']['perfection'] for r in valid_results])

            print(f"\nğŸ¯ æ•´ä½“æ€§èƒ½:")
            print(f"   å¹³å‡å®Œç¾ç‡: {avg_perfection:.4f}")
            print(f"   æ•°æ®æ¥æº: çœŸå®åè®®æ•°æ®é›†")

            # åˆ†æperfectionä½çš„åŸå› 
            print(f"\nğŸ” Perfectionä½çš„å¯èƒ½åŸå› åˆ†æ:")
            print(f"   1. ç®—æ³•æ£€æµ‹çš„è¾¹ç•Œä¸çœŸå®è¾¹ç•Œä¸å®Œå…¨åŒ¹é…")
            print(f"   2. çœŸå®æ•°æ®çš„å­—æ®µè¾¹ç•Œå¯èƒ½éå¸¸å¤æ‚")
            print(f"   3. ç®—æ³•å¯èƒ½è¿‡åº¦åˆ†å‰²æˆ–åˆ†å‰²ä¸è¶³")
            print(f"   4. åè®®ç‰¹å¼‚æ€§è§„åˆ™éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='FieldHunterçœŸå®æ•°æ®å®éªŒ')

    parser.add_argument('--data-root', type=str, default='../../Msg2',
                        help='æ•°æ®æ ¹ç›®å½•è·¯å¾„ (é»˜è®¤: ../../Msg2)')

    parser.add_argument('--protocols', nargs='+',
                        help='è¦æµ‹è¯•çš„åè®®åˆ—è¡¨ (å¦‚æœæœªæŒ‡å®šï¼Œå°†æµ‹è¯•æ‰€æœ‰å¯ç”¨åè®®)')

    parser.add_argument('--max-samples', type=int, default=None,
                        help='æ¯ä¸ªåè®®çš„æœ€å¤§æ ·æœ¬æ•° (å¦‚æœæœªæŒ‡å®šï¼Œå°†ä½¿ç”¨è¯¥åè®®çš„æ‰€æœ‰æ•°æ®)')

    args = parser.parse_args()

    try:
        # æ£€æŸ¥æ•°æ®ç›®å½•
        if not Path(args.data_root).exists():
            print(f"âŒ æ•°æ®æ ¹ç›®å½•ä¸å­˜åœ¨: {args.data_root}")
            print("è¯·ç¡®ä¿æ•°æ®ç›®å½•ç»“æ„å¦‚ä¸‹:")
            print("../../Msg2/")
            print("â””â”€â”€ csv/")
            print("    â”œâ”€â”€ smb/")
            print("    â”œâ”€â”€ dns/")
            print("    â””â”€â”€ ...")
            return

        experiment = RealDataFieldHunterExperiment(data_root=args.data_root)

        print(f"ğŸŒŸ FieldHunterçœŸå®æ•°æ®å®éªŒè®¾ç½®:")
        print(f"   æ•°æ®æ ¹ç›®å½•: {args.data_root}")
        print(f"   å¯ç”¨åè®®: {experiment.protocols}")
        print(f"   æµ‹è¯•åè®®: {args.protocols or 'å…¨éƒ¨'}")
        print(f"   æœ€å¤§æ ·æœ¬: {args.max_samples or 'ä½¿ç”¨å…¨éƒ¨æ•°æ®'}")

        experiment.run_experiments(protocols=args.protocols, max_samples=args.max_samples)
        experiment.generate_report()

        print("\nâœ… FieldHunterçœŸå®æ•°æ®å®éªŒå®Œæˆï¼")

    except Exception as e:
        print(f"âŒ å®éªŒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()