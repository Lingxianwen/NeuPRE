#!/usr/bin/env python3
"""
æ”¹è¿›ç‰ˆNetPlier - çœŸå®æ•°æ®é›†ç‰ˆæœ¬
ä¸»è¦æ”¹è¿›ï¼š
1. ä½¿ç”¨çœŸå®æ•°æ®é›†ï¼ˆ../Msg2/ï¼‰
2. æ™ºèƒ½å­—æ®µåˆå¹¶ç­–ç•¥
3. æ”¹è¿›çš„æ¦‚ç‡æ¨ç†
4. åè®®ç‰¹å¼‚æ€§ä¼˜åŒ–
5. åå¤„ç†è¾¹ç•Œè°ƒæ•´
"""

import os
import sys
import numpy as np
import pandas as pd
import logging
import random
from typing import Dict, List, Tuple, Optional, Set
from collections import defaultdict, Counter
from pathlib import Path
import argparse
from sklearn.metrics import f1_score, accuracy_score
import warnings
import json
import ast

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
warnings.filterwarnings('ignore')


class Message:
    """æ¶ˆæ¯ç±»"""

    def __init__(self, data, source=None, destination=None, timestamp=None):
        self.data = data if isinstance(data, bytes) else bytes.fromhex(data.replace(' ', ''))
        self.source = source or "0.0.0.0:0"
        self.destination = destination or "0.0.0.0:0"
        self.timestamp = timestamp or 0
        self.id = random.randint(1000000, 9999999)


class ImprovedNetPlierDataLoader:
    """æ”¹è¿›çš„æ•°æ®åŠ è½½å™¨ - çœŸå®æ•°æ®é›†ç‰ˆæœ¬"""

    def __init__(self, data_root: str = "../../Msg2"):
        self.data_root = Path(data_root)
        self.csv_root = self.data_root / "csv"
        self.supported_protocols = [
            'smb', 'smb2', 'dns', 's7comm', 'dnp3',
            'modbus', 'ftp', 'tls', 'dhcp'
        ]

    def load_protocol_data(self, protocol_name: str) -> List[Dict]:
        """ä»çœŸå®CSVæ–‡ä»¶åŠ è½½åè®®æ•°æ®"""
        logger.info(f"ğŸ“Š åŠ è½½ {protocol_name.upper()} åè®®æ•°æ®...")

        # æ„å»ºCSVæ–‡ä»¶è·¯å¾„
        csv_path = self.csv_root / protocol_name / f"{protocol_name}.csv"

        if not csv_path.exists():
            logger.warning(f"   âŒ CSVæ–‡ä»¶ä¸å­˜åœ¨: {csv_path}")
            return []

        try:
            # è¯»å–CSVæ–‡ä»¶
            df = pd.read_csv(csv_path)
            logger.info(f"   ğŸ“ æˆåŠŸè¯»å–CSVæ–‡ä»¶: {csv_path}")
            logger.info(f"   ğŸ“Š æ•°æ®è¡Œæ•°: {len(df)}")

            # è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
            data = self._convert_csv_to_standard_format(df, protocol_name)
            logger.info(f"   âœ… æˆåŠŸè½¬æ¢ {len(data)} æ¡æ•°æ®")

            return data

        except Exception as e:
            logger.error(f"   âŒ åŠ è½½CSVæ–‡ä»¶å¤±è´¥: {e}")
            return []

    def _convert_csv_to_standard_format(self, df: pd.DataFrame, protocol_name: str) -> List[Dict]:
        """å°†CSVæ•°æ®è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼"""
        data = []

        for index, row in df.iterrows():
            try:
                # è·å–åŸºæœ¬ä¿¡æ¯
                hex_data = str(row['HexData']).strip()
                length = int(row['Length'])

                # è§£æè¾¹ç•Œä¿¡æ¯
                boundaries_str = str(row['Boundaries']).strip()
                if boundaries_str and boundaries_str != 'nan':
                    # è§£æè¾¹ç•Œå­—ç¬¦ä¸²ï¼Œå¦‚ "2,3,5,7,9,10,11,12,13,14,15,16"
                    boundaries = [int(x.strip()) for x in boundaries_str.split(',')]
                    # ç¡®ä¿è¾¹ç•ŒåŒ…å«èµ·å§‹ä½ç½®å’Œç»“æŸä½ç½®
                    if 0 not in boundaries:
                        boundaries = [0] + boundaries
                    if length not in boundaries:
                        boundaries.append(length)
                    boundaries = sorted(list(set(boundaries)))
                else:
                    # å¦‚æœæ²¡æœ‰è¾¹ç•Œä¿¡æ¯ï¼Œä½¿ç”¨é»˜è®¤è¾¹ç•Œ
                    boundaries = [0, length]

                # éªŒè¯hexæ•°æ®
                try:
                    raw_bytes = bytes.fromhex(hex_data.replace(' ', ''))
                    actual_length = len(raw_bytes)

                    # è°ƒæ•´è¾¹ç•Œä»¥åŒ¹é…å®é™…é•¿åº¦
                    adjusted_boundaries = [b for b in boundaries if b <= actual_length]
                    if actual_length not in adjusted_boundaries:
                        adjusted_boundaries.append(actual_length)

                    sample = {
                        'raw_data': hex_data,
                        'protocol': protocol_name,
                        'bytes': raw_bytes,
                        'length': actual_length,
                        'message_type': row.get('FunctionCode', 'unknown'),
                        'ground_truth_boundaries': sorted(adjusted_boundaries),
                        'original_index': index
                    }
                    data.append(sample)

                except ValueError as e:
                    logger.warning(f"   âš ï¸ è·³è¿‡æ— æ•ˆhexæ•°æ® (è¡Œ{index}): {e}")
                    continue

            except Exception as e:
                logger.warning(f"   âš ï¸ è·³è¿‡å¼‚å¸¸æ•°æ® (è¡Œ{index}): {e}")
                continue

        return data

    def list_available_protocols(self) -> List[str]:
        """åˆ—å‡ºå¯ç”¨çš„åè®®"""
        available_protocols = []

        if self.csv_root.exists():
            for protocol_dir in self.csv_root.iterdir():
                if protocol_dir.is_dir():
                    csv_file = protocol_dir / f"{protocol_dir.name}.csv"
                    if csv_file.exists():
                        available_protocols.append(protocol_dir.name)

        return available_protocols


class ImprovedNetPlierAlgorithm:
    """æ”¹è¿›çš„NetPlierç®—æ³•"""

    def __init__(self):
        self.min_field_size = 1
        self.max_field_size = 64
        self.merge_threshold = 2  # åˆå¹¶å°å­—æ®µçš„é˜ˆå€¼
        self.boundary_tolerance = 1  # è¾¹ç•Œå®¹é”™

        # åè®®ç‰¹å¼‚æ€§å‚æ•°
        self.protocol_params = {
            'dns': {'min_field_size': 2, 'merge_threshold': 1},
            'modbus': {'min_field_size': 1, 'merge_threshold': 2},
            'smb': {'min_field_size': 1, 'merge_threshold': 4},
            'smb2': {'min_field_size': 1, 'merge_threshold': 4},
            'dhcp': {'min_field_size': 1, 'merge_threshold': 3},
            'dnp3': {'min_field_size': 1, 'merge_threshold': 2}
        }

    def extract_fields(self, messages: List[Message], protocol_name: str = None) -> List[List[int]]:
        """æå–å­—æ®µè¾¹ç•Œ - æ”¹è¿›ç‰ˆ"""
        logger.info(f"ğŸ” æ”¹è¿›ç‰ˆNetPlieråˆ†æ {len(messages)} ä¸ªæ¶ˆæ¯...")

        # åº”ç”¨åè®®ç‰¹å¼‚æ€§å‚æ•°
        if protocol_name and protocol_name in self.protocol_params:
            params = self.protocol_params[protocol_name]
            self.min_field_size = params.get('min_field_size', self.min_field_size)
            self.merge_threshold = params.get('merge_threshold', self.merge_threshold)

        # æ­¥éª¤1: æ™ºèƒ½å¤šåºåˆ—æ¯”å¯¹
        aligned_messages = self._intelligent_msa(messages)

        # æ­¥éª¤2: ç”Ÿæˆåˆå§‹å­—æ®µå€™é€‰
        initial_candidates = self._generate_smart_candidates(aligned_messages)

        # æ­¥éª¤3: æ”¹è¿›çš„æ¦‚ç‡æ¨ç†
        keyword_field = self._improved_probabilistic_inference(initial_candidates, aligned_messages)

        # æ­¥éª¤4: åŸºäºå…³é”®å­—æ®µèšç±»
        clusters = self._cluster_by_keyword(aligned_messages, keyword_field, initial_candidates)

        # æ­¥éª¤5: ç”Ÿæˆå¹¶ä¼˜åŒ–è¾¹ç•Œ
        raw_boundaries = self._generate_initial_boundaries(clusters, aligned_messages)

        # æ­¥éª¤6: æ™ºèƒ½åå¤„ç†
        final_boundaries = self._intelligent_postprocessing(raw_boundaries, aligned_messages, protocol_name)

        return final_boundaries

    def _intelligent_msa(self, messages: List[Message]) -> List[bytes]:
        """æ™ºèƒ½å¤šåºåˆ—æ¯”å¯¹"""
        logger.info("   æ‰§è¡Œæ™ºèƒ½å¤šåºåˆ—æ¯”å¯¹...")

        # æŒ‰é•¿åº¦åˆ†ç»„å¤„ç†
        length_groups = defaultdict(list)
        for msg in messages:
            length_groups[len(msg.data)].append(msg.data)

        # æ‰¾åˆ°ä¸»è¦é•¿åº¦ç»„
        main_length = max(length_groups.keys(), key=lambda x: len(length_groups[x]))
        main_group = length_groups[main_length]

        # å¯¹ä¸»è¦ç»„è¿›è¡Œå¯¹é½
        aligned = []
        for msg in messages:
            if len(msg.data) == main_length:
                aligned.append(msg.data)
            elif len(msg.data) < main_length:
                # æ™ºèƒ½å¡«å……
                padded = msg.data + b'\x00' * (main_length - len(msg.data))
                aligned.append(padded)
            else:
                # æ™ºèƒ½æˆªæ–­ï¼ˆä¿ç•™å‰ç¼€ï¼‰
                aligned.append(msg.data[:main_length])

        return aligned

    def _generate_smart_candidates(self, aligned_messages: List[bytes]) -> List[Tuple[int, int]]:
        """ç”Ÿæˆæ™ºèƒ½å­—æ®µå€™é€‰"""
        logger.info("   ç”Ÿæˆæ™ºèƒ½å­—æ®µå€™é€‰...")

        if not aligned_messages:
            return []

        length = len(aligned_messages[0])
        candidates = []

        # åˆ†æå­—èŠ‚ç†µå’Œå˜åŒ–æ¨¡å¼
        entropy_scores = []
        change_points = []

        for pos in range(length):
            values = [msg[pos] for msg in aligned_messages]
            # è®¡ç®—ç†µ
            value_counts = Counter(values)
            entropy = -sum((count / len(values)) * np.log2(count / len(values))
                           for count in value_counts.values() if count > 0)
            entropy_scores.append(entropy)

            # æ£€æµ‹å˜åŒ–ç‚¹
            if pos > 0:
                prev_values = [msg[pos - 1] for msg in aligned_messages]
                change_ratio = sum(1 for v1, v2 in zip(prev_values, values) if v1 != v2) / len(values)
                if change_ratio > 0.3:  # 30%ä»¥ä¸Šçš„æ¶ˆæ¯åœ¨æ­¤ä½ç½®æœ‰å˜åŒ–
                    change_points.append(pos)

        # åŸºäºç†µé˜ˆå€¼æ£€æµ‹è¾¹ç•Œ
        entropy_threshold = np.mean(entropy_scores) + np.std(entropy_scores) * 0.5
        entropy_boundaries = [i for i, entropy in enumerate(entropy_scores) if entropy > entropy_threshold]

        # åˆå¹¶è¾¹ç•Œå€™é€‰
        all_boundaries = sorted(set([0] + change_points + entropy_boundaries + [length]))

        # ç”Ÿæˆå­—æ®µå€™é€‰
        for i in range(len(all_boundaries) - 1):
            start = all_boundaries[i]
            end = all_boundaries[i + 1]
            if end - start >= self.min_field_size:
                candidates.append((start, end))

        # æ·»åŠ å¸¸è§å­—æ®µé•¿åº¦çš„å€™é€‰
        common_sizes = [1, 2, 4, 8, 16]
        for size in common_sizes:
            for start in range(0, length - size, max(1, size // 2)):
                end = start + size
                if end <= length:
                    candidates.append((start, end))

        # å»é‡å¹¶æ’åº
        candidates = sorted(list(set(candidates)))
        logger.info(f"   ç”Ÿæˆäº† {len(candidates)} ä¸ªæ™ºèƒ½å€™é€‰")
        return candidates

    def _improved_probabilistic_inference(self, candidates: List[Tuple[int, int]],
                                          aligned_messages: List[bytes]) -> int:
        """æ”¹è¿›çš„æ¦‚ç‡æ¨ç†"""
        logger.info("   æ‰§è¡Œæ”¹è¿›çš„æ¦‚ç‡æ¨ç†...")

        if not candidates:
            return 0

        best_score = -1
        best_field = 0

        for i, (start, end) in enumerate(candidates):
            field_values = []
            for msg in aligned_messages:
                if end <= len(msg):
                    field_values.append(msg[start:end])

            if not field_values:
                continue

            # æ”¹è¿›çš„è¯„åˆ†å‡½æ•°
            score = self._calculate_improved_field_score(field_values, start, end, len(aligned_messages))

            if score > best_score:
                best_score = score
                best_field = i

        logger.info(f"   é€‰æ‹©å­—æ®µ {best_field} ä½œä¸ºå…³é”®å­—æ®µï¼Œå¾—åˆ†: {best_score:.3f}")
        return best_field

    def _calculate_improved_field_score(self, field_values: List[bytes], start: int, end: int,
                                        total_msgs: int) -> float:
        """è®¡ç®—æ”¹è¿›çš„å­—æ®µå¾—åˆ†"""
        length = end - start
        unique_values = len(set(field_values))
        total_values = len(field_values)

        # 1. å¤šæ ·æ€§å¾—åˆ†ï¼ˆæ”¹è¿›ï¼‰
        if unique_values == 1:
            diversity_score = 0.1  # å¸¸é‡å­—æ®µä¸é€‚åˆåšå…³é”®å­—
        elif unique_values == total_values:
            diversity_score = 0.3  # å®Œå…¨éšæœºä¹Ÿä¸ç†æƒ³
        else:
            # ç†æƒ³çš„å¤šæ ·æ€§åœ¨2-8ä¸ªä¸åŒå€¼ä¹‹é—´
            ideal_diversity = min(8, max(2, total_values // 10))
            diversity_score = 1.0 - abs(unique_values - ideal_diversity) / ideal_diversity
            diversity_score = max(0.1, diversity_score)

        # 2. ä½ç½®å¾—åˆ†ï¼ˆå…³é”®å­—æ®µé€šå¸¸åœ¨å‰é¢ï¼‰
        position_score = 1.0 / (start + 1) if start < 10 else 0.1

        # 3. é•¿åº¦å¾—åˆ†ï¼ˆæ”¹è¿›ï¼‰
        if length == 1:
            length_score = 0.9  # å•å­—èŠ‚å­—æ®µå¾ˆé€‚åˆåšå…³é”®å­—
        elif length == 2:
            length_score = 1.0  # åŒå­—èŠ‚å­—æ®µæœ€ç†æƒ³
        elif length <= 4:
            length_score = 0.7
        elif length <= 8:
            length_score = 0.4
        else:
            length_score = 0.1

        # 4. åˆ†å¸ƒå‡åŒ€æ€§å¾—åˆ†
        value_counts = Counter(field_values)
        max_count = max(value_counts.values())
        min_count = min(value_counts.values())
        if max_count > 0:
            distribution_score = min_count / max_count
        else:
            distribution_score = 0.1

        # 5. è¯­ä¹‰å¾—åˆ†ï¼ˆåŸºäºå¸¸è§æ¨¡å¼ï¼‰
        semantic_score = self._calculate_semantic_score(field_values, start)

        # ç»¼åˆå¾—åˆ†
        total_score = (diversity_score * 0.3 +
                       position_score * 0.2 +
                       length_score * 0.25 +
                       distribution_score * 0.15 +
                       semantic_score * 0.1)

        return total_score

    def _calculate_semantic_score(self, field_values: List[bytes], start: int) -> float:
        """è®¡ç®—è¯­ä¹‰å¾—åˆ†"""
        # æ£€æŸ¥æ˜¯å¦ç¬¦åˆå¸¸è§çš„å…³é”®å­—æ®µæ¨¡å¼
        score = 0.5  # åŸºç¡€åˆ†æ•°

        # å¦‚æœåœ¨å¼€å¤´ï¼Œå¯èƒ½æ˜¯åè®®æ ‡è¯†
        if start == 0:
            score += 0.2

        # æ£€æŸ¥æ˜¯å¦æœ‰æ˜æ˜¾çš„æšä¸¾å€¼æ¨¡å¼
        unique_values = set(field_values)
        if len(unique_values) <= 10 and len(field_values) >= 20:
            score += 0.2

        # æ£€æŸ¥æ•°å€¼èŒƒå›´
        try:
            int_values = [int.from_bytes(v, 'big') for v in field_values if v]
            if int_values:
                value_range = max(int_values) - min(int_values)
                if value_range < 256:  # è¾ƒå°çš„æ•°å€¼èŒƒå›´
                    score += 0.1
        except:
            pass

        return min(1.0, score)

    def _cluster_by_keyword(self, aligned_messages: List[bytes], keyword_field: int,
                            candidates: List[Tuple[int, int]]) -> Dict[bytes, List[int]]:
        """åŸºäºå…³é”®å­—æ®µèšç±»"""
        logger.info("   åŸºäºå…³é”®å­—æ®µèšç±»...")

        clusters = defaultdict(list)

        if keyword_field < len(candidates):
            start, end = candidates[keyword_field]
            for i, msg in enumerate(aligned_messages):
                if end <= len(msg):
                    key = msg[start:end]
                    clusters[key].append(i)
        else:
            # å›é€€åˆ°ç®€å•èšç±»
            for i, msg in enumerate(aligned_messages):
                key = msg[:min(2, len(msg))]
                clusters[key].append(i)

        logger.info(f"   ç”Ÿæˆäº† {len(clusters)} ä¸ªèšç±»")
        return clusters

    def _generate_initial_boundaries(self, clusters: Dict[bytes, List[int]],
                                     aligned_messages: List[bytes]) -> List[List[int]]:
        """ç”Ÿæˆåˆå§‹è¾¹ç•Œ"""
        logger.info("   ç”Ÿæˆåˆå§‹è¾¹ç•Œ...")

        boundaries_list = []

        for i, msg in enumerate(aligned_messages):
            boundaries = self._detect_boundaries_for_message(msg, i, clusters, aligned_messages)
            boundaries_list.append(boundaries)

        return boundaries_list

    def _detect_boundaries_for_message(self, msg: bytes, msg_idx: int,
                                       clusters: Dict[bytes, List[int]],
                                       all_messages: List[bytes]) -> List[int]:
        """ä¸ºå•ä¸ªæ¶ˆæ¯æ£€æµ‹è¾¹ç•Œ"""
        boundaries = [0]

        # åŸºäºå­—èŠ‚å˜åŒ–æ£€æµ‹è¾¹ç•Œ
        for pos in range(1, len(msg)):
            # æ£€æŸ¥å½“å‰ä½ç½®æ˜¯å¦åº”è¯¥æ˜¯è¾¹ç•Œ
            boundary_score = 0

            # 1. å­—èŠ‚å€¼å˜åŒ–
            if pos < len(msg) - 1:
                curr_byte = msg[pos]
                prev_byte = msg[pos - 1]
                next_byte = msg[pos + 1]

                if abs(curr_byte - prev_byte) > 30:
                    boundary_score += 0.3
                if abs(next_byte - curr_byte) > 30:
                    boundary_score += 0.3

            # 2. æ¨¡å¼å˜åŒ–
            if pos >= 2 and pos < len(msg) - 2:
                left_pattern = msg[pos - 2:pos]
                right_pattern = msg[pos:pos + 2]
                if left_pattern != right_pattern:
                    boundary_score += 0.2

            # 3. å¯¹é½ä½ç½®ï¼ˆ2,4,8å­—èŠ‚å¯¹é½ï¼‰
            if pos % 2 == 0:
                boundary_score += 0.1
            if pos % 4 == 0:
                boundary_score += 0.1

            # 4. ä¸å…¶ä»–æ¶ˆæ¯çš„ä¸€è‡´æ€§
            consistency_score = self._check_boundary_consistency(pos, msg_idx, all_messages)
            boundary_score += consistency_score * 0.3

            if boundary_score > 0.5:
                boundaries.append(pos)

        return sorted(boundaries)

    def _check_boundary_consistency(self, pos: int, msg_idx: int, all_messages: List[bytes]) -> float:
        """æ£€æŸ¥è¾¹ç•Œä¸€è‡´æ€§"""
        if pos >= len(all_messages[msg_idx]):
            return 0

        consistent_count = 0
        total_count = 0

        current_byte = all_messages[msg_idx][pos]

        for i, other_msg in enumerate(all_messages):
            if i != msg_idx and pos < len(other_msg):
                total_count += 1
                if other_msg[pos] == current_byte:
                    consistent_count += 1

        return consistent_count / total_count if total_count > 0 else 0

    def _intelligent_postprocessing(self, raw_boundaries: List[List[int]],
                                    aligned_messages: List[bytes],
                                    protocol_name: str = None) -> List[List[int]]:
        """æ™ºèƒ½åå¤„ç†"""
        logger.info("   æ‰§è¡Œæ™ºèƒ½åå¤„ç†...")

        processed_boundaries = []

        for i, boundaries in enumerate(raw_boundaries):
            # æ­¥éª¤1: åˆå¹¶è¿‡å°çš„å­—æ®µ
            merged = self._merge_small_fields(boundaries)

            # æ­¥éª¤2: è°ƒæ•´è¾¹ç•Œåˆ°å¯¹é½ä½ç½®
            aligned = self._align_boundaries(merged, aligned_messages[i])

            # æ­¥éª¤3: åº”ç”¨åè®®ç‰¹å¼‚æ€§è§„åˆ™
            if protocol_name:
                aligned = self._apply_protocol_rules(aligned, protocol_name, aligned_messages[i])

            # æ­¥éª¤4: æœ€ç»ˆéªŒè¯å’Œæ¸…ç†
            final = self._validate_and_clean_boundaries(aligned, aligned_messages[i])

            processed_boundaries.append(final)

        logger.info("   åå¤„ç†å®Œæˆ")
        return processed_boundaries

    def _merge_small_fields(self, boundaries: List[int]) -> List[int]:
        """åˆå¹¶è¿‡å°çš„å­—æ®µ"""
        if len(boundaries) <= 2:
            return boundaries

        merged = [boundaries[0]]

        for i in range(1, len(boundaries)):
            # è®¡ç®—å­—æ®µå¤§å°
            field_size = boundaries[i] - merged[-1]

            if field_size < self.merge_threshold:
                # è·³è¿‡è¿™ä¸ªè¾¹ç•Œï¼Œå®ç°åˆå¹¶
                continue
            else:
                merged.append(boundaries[i])

        return merged

    def _align_boundaries(self, boundaries: List[int], message: bytes) -> List[int]:
        """å°†è¾¹ç•Œå¯¹é½åˆ°åˆé€‚çš„ä½ç½®"""
        aligned = [boundaries[0]]  # ä¿æŒèµ·å§‹ä½ç½®

        for boundary in boundaries[1:]:
            # å°è¯•å¯¹é½åˆ°2å­—èŠ‚è¾¹ç•Œ
            if boundary % 2 == 1 and boundary + 1 < len(message):
                aligned_boundary = boundary + 1
            else:
                aligned_boundary = boundary

            # ç¡®ä¿ä¸ä¸å‰ä¸€ä¸ªè¾¹ç•Œè¿‡äºæ¥è¿‘
            if aligned_boundary - aligned[-1] >= self.min_field_size:
                aligned.append(aligned_boundary)

        return aligned

    def _apply_protocol_rules(self, boundaries: List[int], protocol_name: str, message: bytes) -> List[int]:
        """åº”ç”¨åè®®ç‰¹å¼‚æ€§è§„åˆ™"""

        if protocol_name == 'dns':
            # DNSåè®®ï¼šç¡®ä¿å¤´éƒ¨12å­—èŠ‚å®Œæ•´
            if 12 not in boundaries and 12 < len(message):
                boundaries = sorted(boundaries + [12])

        elif protocol_name == 'modbus':
            # Modbusåè®®ï¼šç¡®ä¿MBAPå¤´éƒ¨7å­—èŠ‚
            if 7 not in boundaries and 7 < len(message):
                boundaries = sorted(boundaries + [7])

        elif protocol_name in ['smb', 'smb2']:
            # SMBåè®®ï¼šç¡®ä¿å¤´éƒ¨å­—æ®µ
            important_positions = [4, 8]
            for pos in important_positions:
                if pos not in boundaries and pos < len(message):
                    boundaries = sorted(boundaries + [pos])

        elif protocol_name == 'dnp3':
            # DNP3åè®®ï¼šç¡®ä¿å¤´éƒ¨å­—æ®µ
            important_positions = [2, 10]
            for pos in important_positions:
                if pos not in boundaries and pos < len(message):
                    boundaries = sorted(boundaries + [pos])

        return boundaries

    def _validate_and_clean_boundaries(self, boundaries: List[int], message: bytes) -> List[int]:
        """éªŒè¯å’Œæ¸…ç†è¾¹ç•Œ"""
        # ç¡®ä¿è¾¹ç•Œåœ¨æœ‰æ•ˆèŒƒå›´å†…
        valid_boundaries = [b for b in boundaries if 0 <= b < len(message)]

        # ç¡®ä¿åŒ…å«èµ·å§‹ä½ç½®
        if 0 not in valid_boundaries:
            valid_boundaries.insert(0, 0)

        # ç§»é™¤é‡å¤è¾¹ç•Œ
        valid_boundaries = sorted(list(set(valid_boundaries)))

        # é™åˆ¶å­—æ®µæ•°é‡ï¼ˆé¿å…è¿‡åº¦åˆ†å‰²ï¼‰
        max_fields = min(10, len(message) // 2)
        if len(valid_boundaries) > max_fields:
            # ä¿ç•™æœ€é‡è¦çš„è¾¹ç•Œ
            valid_boundaries = valid_boundaries[:max_fields]

        return valid_boundaries


class ImprovedNetPlierEvaluator:
    """æ”¹è¿›çš„è¯„ä¼°å™¨"""

    def __init__(self):
        pass

    def evaluate_boundaries(self, predicted_boundaries: List[int],
                            ground_truth_boundaries: List[int],
                            sequence_length: int) -> Dict[str, float]:
        """è¯„ä¼°è¾¹ç•Œæ£€æµ‹æ€§èƒ½"""
        return self._standard_evaluation(predicted_boundaries, ground_truth_boundaries, sequence_length)

    def _standard_evaluation(self, predicted_boundaries: List[int],
                             ground_truth_boundaries: List[int],
                             sequence_length: int) -> Dict[str, float]:
        """æ ‡å‡†è¯„ä¼°"""
        # åˆ›å»ºä½ç½®æ ‡è®°
        pred_positions = set(predicted_boundaries)
        true_positions = set(ground_truth_boundaries)

        # è®¡ç®—å‡†ç¡®ç‡
        correct_positions = 0
        for pos in range(sequence_length):
            pred_is_boundary = pos in pred_positions
            true_is_boundary = pos in true_positions
            if pred_is_boundary == true_is_boundary:
                correct_positions += 1

        accuracy = correct_positions / sequence_length if sequence_length > 0 else 0

        # è®¡ç®—ç²¾ç¡®ç‡å’Œå¬å›ç‡
        if len(predicted_boundaries) > 0:
            true_positives = len(true_positions & pred_positions)
            precision = true_positives / len(predicted_boundaries)
        else:
            precision = 0

        if len(ground_truth_boundaries) > 0:
            true_positives = len(true_positions & pred_positions)
            recall = true_positives / len(ground_truth_boundaries)
        else:
            recall = 0

        # F1åˆ†æ•°
        if precision + recall > 0:
            f1_score = 2 * precision * recall / (precision + recall)
        else:
            f1_score = 0

        # å®Œç¾åŒ¹é…ç‡
        pred_fields = self._boundaries_to_fields(predicted_boundaries, sequence_length)
        true_fields = self._boundaries_to_fields(ground_truth_boundaries, sequence_length)

        if len(true_fields) > 0:
            perfect_matches = len(set(pred_fields) & set(true_fields))
            perfection = perfect_matches / len(true_fields)
        else:
            perfection = 0

        return {
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1_score': f1_score,
            'perfection': perfection
        }

    def _boundaries_to_fields(self, boundaries: List[int], length: int) -> List[Tuple[int, int]]:
        """å°†è¾¹ç•Œè½¬æ¢ä¸ºå­—æ®µ"""
        if not boundaries:
            return [(0, length)] if length > 0 else []

        fields = []
        boundaries = sorted(set(boundaries))

        for i in range(len(boundaries)):
            start = boundaries[i]
            if i < len(boundaries) - 1:
                end = boundaries[i + 1]
            else:
                end = length

            if start < end and start < length:
                fields.append((start, min(end, length)))

        return fields


class ImprovedNetPlierExperiment:
    """æ”¹è¿›çš„å®éªŒç®¡ç†å™¨"""

    def __init__(self, data_root: str = "../../Msg2"):
        self.data_loader = ImprovedNetPlierDataLoader(data_root)
        self.algorithm = ImprovedNetPlierAlgorithm()
        self.evaluator = ImprovedNetPlierEvaluator()

        # è·å–å¯ç”¨åè®®
        self.available_protocols = self.data_loader.list_available_protocols()
        if not self.available_protocols:
            logger.warning("âŒ æœªæ‰¾åˆ°å¯ç”¨çš„åè®®æ•°æ®")
            self.available_protocols = []

        self.results = {}

    def run_experiments(self, protocols: List[str] = None, max_samples: int = None):
        """è¿è¡Œå®éªŒ"""

        if protocols is None:
            protocols = self.available_protocols

        # è¿‡æ»¤å‡ºå¯ç”¨çš„åè®®
        protocols = [p for p in protocols if p in self.available_protocols]

        if not protocols:
            logger.error("âŒ æ²¡æœ‰å¯ç”¨çš„åè®®è¿›è¡Œæµ‹è¯•")
            return

        logger.info("ğŸš€ æ”¹è¿›ç‰ˆNetPlierå®éªŒå¼€å§‹")
        logger.info("=" * 70)

        for protocol in protocols:
            logger.info(f"\nğŸ“Š æµ‹è¯•åè®®: {protocol.upper()}")
            logger.info("-" * 50)

            # åŠ è½½æ•°æ®
            data = self.data_loader.load_protocol_data(protocol)

            if not data:
                logger.warning(f"   âŒ è·³è¿‡ {protocol}: æ— æ•°æ®")
                continue

            # é™åˆ¶æ ·æœ¬æ•°é‡
            if max_samples and len(data) > max_samples:
                data = random.sample(data, max_samples)
                logger.info(f"   ğŸ“ é™åˆ¶æ ·æœ¬æ•°é‡: {max_samples}")

            # è½¬æ¢ä¸ºMessageå¯¹è±¡
            messages = []
            for sample in data:
                msg = Message(sample['raw_data'])
                messages.append(msg)

            try:
                # è¿è¡Œæ”¹è¿›çš„NetPlierç®—æ³•
                logger.info(f"   ğŸ” è¿è¡Œæ”¹è¿›ç‰ˆNetPlierç®—æ³•...")
                predicted_boundaries = self.algorithm.extract_fields(messages, protocol)

                # è¯„ä¼°æ€§èƒ½
                logger.info(f"   ğŸ“ˆ è¯„ä¼°æ€§èƒ½...")
                all_metrics = []

                for sample, pred_boundaries in zip(data, predicted_boundaries):
                    true_boundaries = sample['ground_truth_boundaries']
                    length = sample['length']

                    metrics = self.evaluator.evaluate_boundaries(pred_boundaries, true_boundaries, length)
                    all_metrics.append(metrics)

                # è®¡ç®—å¹³å‡æŒ‡æ ‡
                avg_metrics = {}
                for key in ['accuracy', 'precision', 'recall', 'f1_score', 'perfection']:
                    values = [m[key] for m in all_metrics if not np.isnan(m[key])]
                    avg_metrics[key] = np.mean(values) if values else 0.0

                # ä¿å­˜ç»“æœ
                self.results[protocol] = {
                    'csv_rows': len(data),
                    'metrics': avg_metrics
                }

                # æ˜¾ç¤ºç»“æœ
                logger.info(f"   âœ… ç»“æœ:")
                logger.info(f"      CSVè¡Œæ•°: {len(data)}")
                logger.info(f"      å‡†ç¡®ç‡: {avg_metrics['accuracy']:.4f}")
                logger.info(f"      ç²¾ç¡®ç‡: {avg_metrics['precision']:.4f}")
                logger.info(f"      å¬å›ç‡: {avg_metrics['recall']:.4f}")
                logger.info(f"      F1åˆ†æ•°: {avg_metrics['f1_score']:.4f}")
                logger.info(f"      å®Œç¾ç‡: {avg_metrics['perfection']:.4f}")

            except Exception as e:
                logger.error(f"   âŒ å¤„ç† {protocol} æ—¶å‡ºé”™: {e}")
                self.results[protocol] = {
                    'csv_rows': len(data),
                    'metrics': {'accuracy': 0, 'precision': 0, 'recall': 0,
                                'f1_score': 0, 'perfection': 0},
                    'error': str(e)
                }

    def generate_report(self):
        """ç”ŸæˆæŠ¥å‘Š"""
        logger.info(f"\n" + "=" * 70)
        logger.info("ğŸ“Š æ”¹è¿›ç‰ˆNetPlierå®éªŒæŠ¥å‘Š")
        logger.info("=" * 70)

        if not self.results:
            logger.warning("âŒ æ²¡æœ‰å®éªŒç»“æœ")
            return

        # åˆ›å»ºç»“æœè¡¨æ ¼
        report_data = []
        for protocol, result in self.results.items():
            metrics = result['metrics']
            report_data.append({
                'Protocol': protocol.upper(),
                'CSV_Rows': result['csv_rows'],
                'Accuracy': f"{metrics['accuracy']:.4f}",
                'Precision': f"{metrics['precision']:.4f}",
                'Recall': f"{metrics['recall']:.4f}",
                'F1-score': f"{metrics['f1_score']:.4f}",
                'Perfection': f"{metrics['perfection']:.4f}"
            })

        # æ˜¾ç¤ºè¡¨æ ¼
        df = pd.DataFrame(report_data)
        print("\nå®éªŒç»“æœè¡¨æ ¼:")
        print(df.to_string(index=False))

        # è®¡ç®—æ€»ä½“ç»Ÿè®¡
        logger.info(f"\nğŸ¯ æ€»ä½“ç»Ÿè®¡:")
        total_samples = sum(r['csv_rows'] for r in self.results.values())
        avg_accuracy = np.mean([r['metrics']['accuracy'] for r in self.results.values()])
        avg_precision = np.mean([r['metrics']['precision'] for r in self.results.values()])
        avg_recall = np.mean([r['metrics']['recall'] for r in self.results.values()])
        avg_f1 = np.mean([r['metrics']['f1_score'] for r in self.results.values()])
        avg_perfection = np.mean([r['metrics']['perfection'] for r in self.results.values()])

        logger.info(f"   æ€»æ ·æœ¬æ•°: {total_samples}")
        logger.info(f"   å¹³å‡å‡†ç¡®ç‡: {avg_accuracy:.4f}")
        logger.info(f"   å¹³å‡ç²¾ç¡®ç‡: {avg_precision:.4f}")
        logger.info(f"   å¹³å‡å¬å›ç‡: {avg_recall:.4f}")
        logger.info(f"   å¹³å‡F1åˆ†æ•°: {avg_f1:.4f}")
        logger.info(f"   å¹³å‡å®Œç¾ç‡: {avg_perfection:.4f}")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='æ”¹è¿›ç‰ˆNetPlierå®éªŒ - çœŸå®æ•°æ®é›†ç‰ˆæœ¬')

    parser.add_argument('--data-root', type=str, default="../../Msg2",
                        help='æ•°æ®é›†æ ¹ç›®å½•')

    parser.add_argument('--protocols', nargs='+',
                        help='è¦æµ‹è¯•çš„åè®®åˆ—è¡¨')

    parser.add_argument('--max-samples', type=int, default=None,
                        help='æ¯ä¸ªåè®®çš„æœ€å¤§æ ·æœ¬æ•°')

    parser.add_argument('--list-protocols', action='store_true',
                        help='åˆ—å‡ºå¯ç”¨çš„åè®®')

    args = parser.parse_args()

    # åˆ›å»ºå®éªŒç®¡ç†å™¨
    experiment = ImprovedNetPlierExperiment(args.data_root)

    # åˆ—å‡ºå¯ç”¨åè®®
    if args.list_protocols:
        available_protocols = experiment.data_loader.list_available_protocols()
        logger.info(f"ğŸ“‹ å¯ç”¨åè®®: {available_protocols}")
        return

    logger.info(f"ğŸŒŸ æ”¹è¿›ç‰ˆNetPlierå®éªŒè®¾ç½®:")
    logger.info(f"   æ•°æ®æ ¹ç›®å½•: {args.data_root}")
    logger.info(f"   å¯ç”¨åè®®: {experiment.available_protocols}")
    logger.info(f"   æµ‹è¯•åè®®: {args.protocols or 'ALL'}")
    logger.info(f"   æœ€å¤§æ ·æœ¬: {args.max_samples or 'UNLIMITED'}")

    # è¿è¡Œå®éªŒ
    experiment.run_experiments(protocols=args.protocols, max_samples=args.max_samples)

    # ç”ŸæˆæŠ¥å‘Š
    experiment.generate_report()

    logger.info("\nâœ… æ”¹è¿›ç‰ˆNetPlierå®éªŒå®Œæˆï¼")
    logger.info("\nğŸ‰ ä¸»è¦ç‰¹æ€§:")
    logger.info("   1. ä½¿ç”¨çœŸå®æ•°æ®é›†")
    logger.info("   2. æ™ºèƒ½å­—æ®µåˆå¹¶ç­–ç•¥")
    logger.info("   3. æ”¹è¿›çš„æ¦‚ç‡æ¨ç†")
    logger.info("   4. åè®®ç‰¹å¼‚æ€§ä¼˜åŒ–")
    logger.info("   5. æ™ºèƒ½åå¤„ç†")


if __name__ == "__main__":
    main()