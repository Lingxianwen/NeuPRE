#!/usr/bin/env python3
"""
ä¿®å¤ç‰ˆNetzobå®éªŒä»£ç  - è§£å†³PerfectionæŒ‡æ ‡ä½çš„é—®é¢˜
ä¸»è¦ä¿®å¤å†…å®¹ï¼š
1. ä¿®å¤è¾¹ç•Œæ£€æµ‹ç®—æ³•ï¼Œæé«˜ç²¾ç¡®åº¦
2. æ”¹è¿›å­—æ®µåŒ¹é…é€»è¾‘
3. ä¼˜åŒ–åè®®ç‰¹å¼‚æ€§è¾¹ç•Œæ£€æµ‹
4. å¢å¼ºground truthè¾¹ç•Œè§£æ
5. ä¿®å¤å®Œç¾åŒ¹é…è¯„ä¼°ç®—æ³•
"""

import os
import sys
import numpy as np
import pandas as pd
import logging
import random
from typing import Dict, List, Tuple, Optional, Set
from collections import defaultdict, Counter
from pathlib import Path
import argparse
from sklearn.metrics import f1_score, accuracy_score
from sklearn.cluster import KMeans
import warnings
from itertools import combinations
import glob

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
warnings.filterwarnings('ignore')


class Message:
    """æ¶ˆæ¯ç±»"""

    def __init__(self, data, source=None, destination=None, timestamp=None):
        self.data = data if isinstance(data, bytes) else bytes.fromhex(data.replace(' ', ''))
        self.source = source or "0.0.0.0:0"
        self.destination = destination or "0.0.0.0:0"
        self.timestamp = timestamp or 0
        self.id = random.randint(1000000, 9999999)


class RealDatasetLoader:
    """çœŸå®æ•°æ®é›†åŠ è½½å™¨ - å¢å¼ºè¾¹ç•Œè§£æ"""

    def __init__(self, data_root: str = "../../Msg2"):
        self.data_root = Path(data_root)
        self.csv_root = self.data_root / "csv"
        self.txt_root = self.data_root / "txt"

        # æ”¯æŒçš„åè®®åˆ—è¡¨
        self.supported_protocols = [
            'smb', 'smb2', 'dns', 's7comm', 'dnp3',
            'modbus', 'ftp', 'tls', 'dhcp'
        ]

    def load_protocol_data(self, protocol_name: str) -> List[Dict]:
        """åŠ è½½åè®®æ•°æ®ä»CSVæ–‡ä»¶"""
        logger.info(f"ğŸ“Š åŠ è½½ {protocol_name.upper()} åè®®æ•°æ®...")

        # æ£€æŸ¥CSVæ–‡ä»¶å¤¹
        csv_protocol_dir = self.csv_root / protocol_name
        if not csv_protocol_dir.exists():
            logger.warning(f"   âŒ CSVç›®å½•ä¸å­˜åœ¨: {csv_protocol_dir}")
            return []

        # æŸ¥æ‰¾CSVæ–‡ä»¶
        csv_files = list(csv_protocol_dir.glob("*.csv"))
        if not csv_files:
            logger.warning(f"   âŒ æ²¡æœ‰æ‰¾åˆ°CSVæ–‡ä»¶: {csv_protocol_dir}")
            return []

        data = []
        for csv_file in csv_files:
            try:
                file_data = self._load_csv_file(csv_file, protocol_name)
                data.extend(file_data)
                logger.info(f"   âœ… ä» {csv_file.name} åŠ è½½ {len(file_data)} æ¡æ•°æ®")
            except Exception as e:
                logger.error(f"   âŒ åŠ è½½CSVæ–‡ä»¶ {csv_file} å¤±è´¥: {e}")
                continue

        logger.info(f"   ğŸ“ˆ æ€»è®¡åŠ è½½ {len(data)} æ¡ {protocol_name.upper()} æ•°æ®")
        return data

    def _load_csv_file(self, csv_file: Path, protocol_name: str) -> List[Dict]:
        """åŠ è½½å•ä¸ªCSVæ–‡ä»¶"""
        data = []

        try:
            # è¯»å–CSVæ–‡ä»¶
            df = pd.read_csv(csv_file)
            logger.info(f"   ğŸ“‹ CSVæ–‡ä»¶ {csv_file.name} åŒ…å« {len(df)} è¡Œæ•°æ®")

            # æ£€æŸ¥å¿…è¦çš„åˆ—
            required_columns = self._get_required_columns(df.columns.tolist())
            if not required_columns:
                logger.warning(f"   âš ï¸ CSVæ–‡ä»¶ç¼ºå°‘å¿…è¦åˆ—ï¼Œå°è¯•è‡ªåŠ¨æ¨æ–­...")
                required_columns = self._infer_columns(df.columns.tolist())

            # æ‰“å°åˆ—ä¿¡æ¯ç”¨äºè°ƒè¯•
            logger.debug(f"   ğŸ” CSVåˆ—: {df.columns.tolist()}")
            logger.debug(f"   ğŸ” æ˜ å°„åˆ—: {required_columns}")

            # å¤„ç†æ¯ä¸€è¡Œæ•°æ®
            for index, row in df.iterrows():
                try:
                    sample = self._parse_csv_row(row, index, protocol_name, required_columns)
                    if sample:
                        data.append(sample)
                except Exception as e:
                    logger.debug(f"   âš ï¸ è§£æç¬¬ {index} è¡Œå¤±è´¥: {e}")
                    continue

        except Exception as e:
            logger.error(f"   âŒ è¯»å–CSVæ–‡ä»¶å¤±è´¥: {e}")

        return data

    def _get_required_columns(self, columns: List[str]) -> Dict[str, str]:
        """è·å–å¿…è¦çš„åˆ—åæ˜ å°„"""
        column_mapping = {}

        # å¸¸è§çš„åˆ—åæ¨¡å¼ï¼ˆæ›´å…¨é¢çš„åŒ¹é…ï¼‰
        hex_patterns = ['hex', 'data', 'payload', 'raw_data', 'hex_data', 'message', 'packet', 'frame']
        boundary_patterns = ['boundary', 'boundaries', 'fields', 'ground_truth', 'label', 'labels', 'field_boundaries',
                             'gt_boundaries']

        for col in columns:
            col_lower = col.lower().strip()

            # æŸ¥æ‰¾HEXæ•°æ®åˆ—
            if not column_mapping.get('hex_data'):
                for pattern in hex_patterns:
                    if pattern in col_lower:
                        column_mapping['hex_data'] = col
                        break

            # æŸ¥æ‰¾è¾¹ç•Œæ ‡ç­¾åˆ—
            if not column_mapping.get('boundaries'):
                for pattern in boundary_patterns:
                    if pattern in col_lower:
                        column_mapping['boundaries'] = col
                        break

        return column_mapping

    def _infer_columns(self, columns: List[str]) -> Dict[str, str]:
        """æ¨æ–­åˆ—å"""
        column_mapping = {}

        # å¦‚æœåªæœ‰å°‘æ•°å‡ åˆ—ï¼Œå°è¯•æ¨æ–­
        if len(columns) >= 1:
            column_mapping['hex_data'] = columns[0]  # ç¬¬ä¸€åˆ—é€šå¸¸æ˜¯æ•°æ®

        if len(columns) >= 2:
            column_mapping['boundaries'] = columns[1]  # ç¬¬äºŒåˆ—å¯èƒ½æ˜¯æ ‡ç­¾

        return column_mapping

    def _parse_csv_row(self, row: pd.Series, row_index: int, protocol_name: str, column_mapping: Dict[str, str]) -> \
    Optional[Dict]:
        """è§£æCSVè¡Œæ•°æ® - å¢å¼ºè¾¹ç•Œè§£æ"""
        try:
            # è·å–HEXæ•°æ®
            hex_data = None
            if 'hex_data' in column_mapping:
                hex_data = str(row[column_mapping['hex_data']]).strip()
            else:
                # å°è¯•ä»ç¬¬ä¸€åˆ—è·å–
                hex_data = str(row.iloc[0]).strip()

            if not hex_data or hex_data.lower() in ['nan', 'none', '']:
                return None

            # æ¸…ç†HEXæ•°æ®
            hex_data = self._clean_hex_data(hex_data)
            if not hex_data:
                return None

            # è½¬æ¢ä¸ºå­—èŠ‚
            try:
                raw_bytes = bytes.fromhex(hex_data)
            except ValueError as e:
                logger.debug(f"   âš ï¸ ç¬¬ {row_index} è¡ŒHEXæ•°æ®æ ¼å¼é”™è¯¯: {e}")
                return None

            # è·å–è¾¹ç•Œæ ‡ç­¾ï¼ˆå…³é”®ä¿®å¤ï¼‰
            boundaries = self._parse_boundaries_enhanced(row, column_mapping, len(raw_bytes), protocol_name)

            # åˆ›å»ºæ ·æœ¬
            sample = {
                'raw_data': hex_data,
                'protocol': protocol_name,
                'bytes': raw_bytes,
                'length': len(raw_bytes),
                'message_type': f'real_{protocol_name}',
                'ground_truth_boundaries': boundaries,
                'source': f'csv_row_{row_index}',
                'row_index': row_index
            }

            return sample

        except Exception as e:
            logger.debug(f"   âš ï¸ è§£æç¬¬ {row_index} è¡Œå¤±è´¥: {e}")
            return None

    def _clean_hex_data(self, hex_data: str) -> str:
        """æ¸…ç†HEXæ•°æ®"""
        # ç§»é™¤ç©ºæ ¼ã€å†’å·ã€è¿å­—ç¬¦ç­‰
        hex_data = hex_data.replace(' ', '').replace(':', '').replace('-', '')

        # åªä¿ç•™æœ‰æ•ˆçš„HEXå­—ç¬¦
        hex_data = ''.join(c for c in hex_data if c in '0123456789abcdefABCDEF')

        # ç¡®ä¿é•¿åº¦ä¸ºå¶æ•°
        if len(hex_data) % 2 != 0:
            hex_data = '0' + hex_data

        return hex_data

    def _parse_boundaries_enhanced(self, row: pd.Series, column_mapping: Dict[str, str],
                                   length: int, protocol_name: str) -> List[int]:
        """å¢å¼ºçš„è¾¹ç•Œè§£æç®—æ³•"""
        boundaries = [0]  # æ€»æ˜¯åŒ…å«èµ·å§‹ä½ç½®

        try:
            # 1. å°è¯•ä»æŒ‡å®šåˆ—è·å–è¾¹ç•Œ
            if 'boundaries' in column_mapping:
                boundary_data = str(row[column_mapping['boundaries']]).strip()
                if boundary_data and boundary_data.lower() not in ['nan', 'none', '']:
                    parsed_boundaries = self._parse_boundary_string_enhanced(boundary_data, length)
                    if parsed_boundaries:
                        boundaries.extend(parsed_boundaries)
                        logger.debug(f"   ğŸ” ä»CSVè§£æè¾¹ç•Œ: {parsed_boundaries}")

            # 2. å¦‚æœæ²¡æœ‰æ‰¾åˆ°è¾¹ç•Œæ ‡ç­¾ï¼Œä½¿ç”¨åè®®æ ‡å‡†è¾¹ç•Œ
            if len(boundaries) == 1:
                standard_boundaries = self._get_protocol_standard_boundaries(protocol_name, length)
                boundaries.extend(standard_boundaries)
                logger.debug(f"   ğŸ” ä½¿ç”¨åè®®æ ‡å‡†è¾¹ç•Œ: {standard_boundaries}")

        except Exception as e:
            logger.debug(f"   âš ï¸ è§£æè¾¹ç•Œå¤±è´¥: {e}")
            # ä½¿ç”¨åè®®æ ‡å‡†è¾¹ç•Œ
            standard_boundaries = self._get_protocol_standard_boundaries(protocol_name, length)
            boundaries.extend(standard_boundaries)

        # ç¡®ä¿åŒ…å«ç»“æŸä½ç½®
        if length not in boundaries:
            boundaries.append(length)

        # å»é‡å¹¶æ’åº
        boundaries = sorted(list(set(boundaries)))

        return boundaries

    def _parse_boundary_string_enhanced(self, boundary_str: str, length: int) -> List[int]:
        """å¢å¼ºçš„è¾¹ç•Œå­—ç¬¦ä¸²è§£æ"""
        boundaries = []

        try:
            # æ¸…ç†è¾¹ç•Œå­—ç¬¦ä¸²
            boundary_str = boundary_str.strip('[](){}"\'')

            # å°è¯•ä¸åŒçš„åˆ†éš”ç¬¦
            separators = [',', ';', ' ', '|', '\t', '-', '_']

            for sep in separators:
                if sep in boundary_str:
                    parts = boundary_str.split(sep)
                    for part in parts:
                        part = part.strip()
                        # å°è¯•è§£æä¸ºæ•´æ•°
                        try:
                            pos = int(part)
                            if 0 <= pos <= length:
                                boundaries.append(pos)
                        except ValueError:
                            # å°è¯•è§£æä¸ºèŒƒå›´ (ä¾‹å¦‚ "0-4")
                            if '-' in part and sep != '-':
                                range_parts = part.split('-')
                                if len(range_parts) == 2:
                                    try:
                                        start = int(range_parts[0])
                                        end = int(range_parts[1])
                                        if 0 <= start <= length:
                                            boundaries.append(start)
                                        if 0 <= end <= length and end != start:
                                            boundaries.append(end)
                                    except ValueError:
                                        continue
                    break

            # å¦‚æœæ²¡æœ‰åˆ†éš”ç¬¦ï¼Œå°è¯•è§£æå•ä¸ªæ•°å­—
            if not boundaries and boundary_str.isdigit():
                pos = int(boundary_str)
                if 0 <= pos <= length:
                    boundaries.append(pos)

        except Exception as e:
            logger.debug(f"   âš ï¸ è§£æè¾¹ç•Œå­—ç¬¦ä¸²å¤±è´¥: {e}")

        return boundaries

    def _get_protocol_standard_boundaries(self, protocol_name: str, length: int) -> List[int]:
        """è·å–åè®®æ ‡å‡†è¾¹ç•Œ - åŸºäºRFCè§„èŒƒ"""
        boundaries = []

        if protocol_name == 'dns':
            # DNSæ ‡å‡†å­—æ®µè¾¹ç•Œ
            standard_positions = [2, 4, 6, 8, 10,
                                  12]  # Transaction ID, Flags, Questions, Answers, Authority, Additional
            boundaries.extend([pos for pos in standard_positions if pos < length])

        elif protocol_name == 'modbus':
            # Modbus TCPæ ‡å‡†å­—æ®µè¾¹ç•Œ
            standard_positions = [2, 4, 6, 7, 8]  # Transaction ID, Protocol ID, Length, Unit ID, Function Code
            boundaries.extend([pos for pos in standard_positions if pos < length])

        elif protocol_name in ['smb', 'smb2']:
            # SMBæ ‡å‡†å­—æ®µè¾¹ç•Œ
            if protocol_name == 'smb':
                standard_positions = [4, 5, 6, 8]  # Protocol, Command, Status, Flags
            else:  # smb2
                standard_positions = [4, 6, 8, 12, 16]  # Header Length, Credit, Command, Flags, Chain Offset
            boundaries.extend([pos for pos in standard_positions if pos < length])

        elif protocol_name == 'dhcp':
            # DHCPæ ‡å‡†å­—æ®µè¾¹ç•Œ
            standard_positions = [1, 2, 3, 4, 8, 12, 16, 20, 24, 28]  # Op, HType, HLen, Hops, XID, Secs, Flags, etc.
            boundaries.extend([pos for pos in standard_positions if pos < length])

        elif protocol_name == 'dnp3':
            # DNP3æ ‡å‡†å­—æ®µè¾¹ç•Œ
            standard_positions = [2, 3, 4, 6, 8, 10]  # Start, Length, Control, Destination, Source, CRC
            boundaries.extend([pos for pos in standard_positions if pos < length])

        elif protocol_name == 'ftp':
            # FTPè¾ƒç®€å•ï¼Œé€šå¸¸æ˜¯å›ºå®šçš„å‡ ä¸ªå­—æ®µ
            standard_positions = [2, 4]
            boundaries.extend([pos for pos in standard_positions if pos < length])

        elif protocol_name == 'tls':
            # TLSè®°å½•å±‚æ ‡å‡†è¾¹ç•Œ
            standard_positions = [1, 3, 5]  # Content Type, Version, Length
            boundaries.extend([pos for pos in standard_positions if pos < length])

        else:
            # é»˜è®¤ï¼šæ¯2å­—èŠ‚ä¸€ä¸ªè¾¹ç•Œï¼ˆæ›´ä¿å®ˆï¼‰
            for i in range(2, min(length, 16), 2):  # é™åˆ¶åœ¨å‰16å­—èŠ‚
                boundaries.append(i)

        return boundaries

    def get_available_protocols(self) -> List[str]:
        """è·å–å¯ç”¨çš„åè®®åˆ—è¡¨"""
        available = []

        if self.csv_root.exists():
            for protocol_dir in self.csv_root.iterdir():
                if protocol_dir.is_dir() and protocol_dir.name in self.supported_protocols:
                    csv_files = list(protocol_dir.glob("*.csv"))
                    if csv_files:
                        available.append(protocol_dir.name)

        return available


class EnhancedNetzobAlgorithm:
    """å¢å¼ºç‰ˆNetzobç®—æ³• - ä¸“æ³¨æé«˜PerfectionæŒ‡æ ‡"""

    def __init__(self):
        # è°ƒæ•´å‚æ•°ä»¥æé«˜ç²¾ç¡®åº¦
        self.min_field_size = 1
        self.max_field_size = 32
        self.merge_threshold = 2  # é™ä½åˆå¹¶é˜ˆå€¼ï¼Œä¿ç•™æ›´å¤šè¾¹ç•Œ
        self.max_fields = 12  # å¢åŠ æœ€å¤§å­—æ®µæ•°
        self.boundary_quality_threshold = 0.5  # é™ä½è´¨é‡é˜ˆå€¼ï¼ŒåŒ…å«æ›´å¤šå€™é€‰
        self.statistical_threshold = 1.5  # é™ä½ç»Ÿè®¡é˜ˆå€¼

    def extract_fields(self, messages: List[Message], protocol_name: str = None) -> List[List[int]]:
        """å¢å¼ºç‰ˆNetzobå­—æ®µæå–ç®—æ³•"""
        logger.info(f"ğŸ” å¢å¼ºç‰ˆNetzobç®—æ³•åˆ†æ {len(messages)} ä¸ªæ¶ˆæ¯...")

        # æ­¥éª¤1: åºåˆ—å¯¹é½å’Œé¢„å¤„ç†
        aligned_sequences = self._sequence_alignment_enhanced(messages)

        # æ­¥éª¤2: å¤šç­–ç•¥è¾¹ç•Œæ£€æµ‹
        boundary_candidates = self._multi_strategy_boundary_detection(aligned_sequences, protocol_name)

        # æ­¥éª¤3: æ™ºèƒ½è¾¹ç•Œç­›é€‰å’Œç»„åˆ
        selected_boundaries = self._intelligent_boundary_combination(boundary_candidates, aligned_sequences,
                                                                     protocol_name)

        # æ­¥éª¤4: å­—æ®µéªŒè¯å’Œä¼˜åŒ–
        final_boundaries = self._field_validation_and_optimization(selected_boundaries, aligned_sequences,
                                                                   protocol_name)

        return final_boundaries

    def _sequence_alignment_enhanced(self, messages: List[Message]) -> List[bytes]:
        """å¢å¼ºçš„åºåˆ—å¯¹é½"""
        logger.info("   å¢å¼ºåºåˆ—å¯¹é½...")

        if not messages:
            return []

        # åˆ†æé•¿åº¦åˆ†å¸ƒ
        length_counter = Counter(len(msg.data) for msg in messages)
        most_common_lengths = length_counter.most_common(3)

        logger.info(f"   æœ€å¸¸è§é•¿åº¦: {most_common_lengths}")

        # é€‰æ‹©æœ€é€‚åˆçš„å‚è€ƒé•¿åº¦
        if most_common_lengths:
            reference_length = most_common_lengths[0][0]
        else:
            reference_length = max(len(msg.data) for msg in messages)

        aligned = []
        for msg in messages:
            if len(msg.data) == reference_length:
                aligned.append(msg.data)
            elif len(msg.data) < reference_length:
                # å¡«å……é›¶å­—èŠ‚
                aligned.append(msg.data + b'\x00' * (reference_length - len(msg.data)))
            else:
                # æˆªæ–­åˆ°å‚è€ƒé•¿åº¦
                aligned.append(msg.data[:reference_length])

        logger.info(f"   å¯¹é½å®Œæˆï¼Œå‚è€ƒé•¿åº¦: {reference_length}, å¯¹é½æ¶ˆæ¯æ•°: {len(aligned)}")
        return aligned

    def _multi_strategy_boundary_detection(self, aligned_sequences: List[bytes], protocol_name: str) -> Dict[
        str, List[int]]:
        """å¤šç­–ç•¥è¾¹ç•Œæ£€æµ‹"""
        logger.info("   å¤šç­–ç•¥è¾¹ç•Œæ£€æµ‹...")

        if not aligned_sequences:
            return {'combined': [0]}

        length = len(aligned_sequences[0])
        strategies = {}

        # ç­–ç•¥1: åè®®æ ‡å‡†è¾¹ç•Œ
        if protocol_name:
            protocol_boundaries = self._get_protocol_specific_boundaries(protocol_name, length)
            strategies['protocol'] = protocol_boundaries
            logger.info(f"   åè®®è¾¹ç•Œ({protocol_name}): {len(protocol_boundaries)} ä¸ª")

        # ç­–ç•¥2: ç»Ÿè®¡å˜åŒ–ç‚¹æ£€æµ‹
        statistical_boundaries = self._detect_statistical_change_points(aligned_sequences)
        strategies['statistical'] = statistical_boundaries
        logger.info(f"   ç»Ÿè®¡è¾¹ç•Œ: {len(statistical_boundaries)} ä¸ª")

        # ç­–ç•¥3: å­—èŠ‚å¯¹é½è¾¹ç•Œ
        alignment_boundaries = self._detect_alignment_boundaries(length)
        strategies['alignment'] = alignment_boundaries
        logger.info(f"   å¯¹é½è¾¹ç•Œ: {len(alignment_boundaries)} ä¸ª")

        # ç­–ç•¥4: ç†µå˜åŒ–æ£€æµ‹
        entropy_boundaries = self._detect_entropy_changes(aligned_sequences)
        strategies['entropy'] = entropy_boundaries
        logger.info(f"   ç†µå˜åŒ–è¾¹ç•Œ: {len(entropy_boundaries)} ä¸ª")

        # ç»„åˆæ‰€æœ‰ç­–ç•¥
        combined_boundaries = [0]  # èµ·å§‹ä½ç½®
        for strategy_boundaries in strategies.values():
            combined_boundaries.extend(strategy_boundaries)

        combined_boundaries = sorted(list(set(combined_boundaries)))
        strategies['combined'] = combined_boundaries

        logger.info(f"   ç»„åˆè¾¹ç•Œ: {len(combined_boundaries)} ä¸ª")
        return strategies

    def _get_protocol_specific_boundaries(self, protocol_name: str, length: int) -> List[int]:
        """è·å–åè®®ç‰¹å®šè¾¹ç•Œ"""
        boundaries = []

        protocol_specs = {
            'dns': [2, 4, 6, 8, 10, 12],
            'modbus': [2, 4, 6, 7, 8],
            'smb': [4, 5, 6, 8, 32],
            'smb2': [4, 6, 8, 12, 16, 20, 24],
            'dhcp': [1, 2, 3, 4, 8, 12, 16, 20, 24, 28],
            'dnp3': [2, 3, 4, 6, 8, 10],
            'ftp': [2, 4],
            'tls': [1, 3, 5, 6, 9],
            's7comm': [2, 4, 6, 8, 10, 12]
        }

        if protocol_name in protocol_specs:
            boundaries = [pos for pos in protocol_specs[protocol_name] if pos < length]

        return boundaries

    def _detect_statistical_change_points(self, aligned_sequences: List[bytes]) -> List[int]:
        """æ£€æµ‹ç»Ÿè®¡å˜åŒ–ç‚¹"""
        boundaries = []
        if not aligned_sequences:
            return boundaries

        length = len(aligned_sequences[0])

        for pos in range(1, length):
            # è®¡ç®—ä½ç½®å‰åçš„ç»Ÿè®¡å·®å¼‚
            values_before = []
            values_after = []

            for seq in aligned_sequences:
                if pos < len(seq):
                    if pos > 0:
                        values_before.append(seq[pos - 1])
                    if pos < len(seq):
                        values_after.append(seq[pos])

            if values_before and values_after:
                # è®¡ç®—ç»Ÿè®¡å·®å¼‚
                variance_before = np.var(values_before) if len(values_before) > 1 else 0
                variance_after = np.var(values_after) if len(values_after) > 1 else 0

                # å¦‚æœæ–¹å·®å˜åŒ–æ˜¾è‘—ï¼Œå¯èƒ½æ˜¯è¾¹ç•Œ
                if abs(variance_before - variance_after) > self.statistical_threshold:
                    boundaries.append(pos)

        return boundaries

    def _detect_alignment_boundaries(self, length: int) -> List[int]:
        """æ£€æµ‹å¯¹é½è¾¹ç•Œ"""
        boundaries = []

        # 4å­—èŠ‚å¯¹é½ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰
        for pos in range(4, length, 4):
            boundaries.append(pos)

        # 2å­—èŠ‚å¯¹é½
        for pos in range(2, length, 2):
            if pos not in boundaries:
                boundaries.append(pos)

        return sorted(boundaries)

    def _detect_entropy_changes(self, aligned_sequences: List[bytes]) -> List[int]:
        """æ£€æµ‹ç†µå˜åŒ–è¾¹ç•Œ"""
        boundaries = []
        if not aligned_sequences:
            return boundaries

        length = len(aligned_sequences[0])
        entropies = []

        # è®¡ç®—æ¯ä¸ªä½ç½®çš„ç†µ
        for pos in range(length):
            values = [seq[pos] for seq in aligned_sequences if pos < len(seq)]
            if values:
                entropy = self._calculate_entropy(values)
                entropies.append(entropy)
            else:
                entropies.append(0)

        # æ£€æµ‹ç†µçš„æ˜¾è‘—å˜åŒ–
        for i in range(1, len(entropies)):
            if abs(entropies[i] - entropies[i - 1]) > 0.5:  # ç†µå˜åŒ–é˜ˆå€¼
                boundaries.append(i)

        return boundaries

    def _calculate_entropy(self, values: List[int]) -> float:
        """è®¡ç®—ç†µ"""
        if not values:
            return 0.0

        value_counts = Counter(values)
        total = len(values)

        entropy = 0.0
        for count in value_counts.values():
            if count > 0:
                prob = count / total
                entropy -= prob * np.log2(prob)

        return entropy

    def _intelligent_boundary_combination(self, boundary_strategies: Dict[str, List[int]],
                                          aligned_sequences: List[bytes],
                                          protocol_name: str) -> List[List[int]]:
        """æ™ºèƒ½è¾¹ç•Œç»„åˆå’Œç­›é€‰"""
        logger.info("   æ™ºèƒ½è¾¹ç•Œç»„åˆ...")

        boundaries_list = []

        for seq in aligned_sequences:
            seq_length = len(seq)

            # ä¸ºæ¯ä¸ªåºåˆ—é€‰æ‹©æœ€ä½³è¾¹ç•Œç»„åˆ
            best_boundaries = self._select_best_boundaries_for_sequence(
                boundary_strategies, seq, protocol_name
            )

            # ç¡®ä¿è¾¹ç•Œæœ‰æ•ˆæ€§
            valid_boundaries = [b for b in best_boundaries if 0 <= b <= seq_length]

            # ç¡®ä¿åŒ…å«èµ·å§‹å’Œç»“æŸä½ç½®
            if 0 not in valid_boundaries:
                valid_boundaries.insert(0, 0)
            if seq_length not in valid_boundaries:
                valid_boundaries.append(seq_length)

            valid_boundaries = sorted(list(set(valid_boundaries)))
            boundaries_list.append(valid_boundaries)

        return boundaries_list

    def _select_best_boundaries_for_sequence(self, boundary_strategies: Dict[str, List[int]],
                                             sequence: bytes, protocol_name: str) -> List[int]:
        """ä¸ºå•ä¸ªåºåˆ—é€‰æ‹©æœ€ä½³è¾¹ç•Œ"""
        seq_length = len(sequence)

        # ä¼˜å…ˆçº§æƒé‡
        strategy_weights = {
            'protocol': 0.4,  # åè®®æ ‡å‡†è¾¹ç•Œæƒé‡æœ€é«˜
            'statistical': 0.3,
            'alignment': 0.2,
            'entropy': 0.1
        }

        # å€™é€‰è¾¹ç•Œè¯„åˆ†
        boundary_scores = defaultdict(float)

        for strategy, boundaries in boundary_strategies.items():
            if strategy == 'combined':
                continue

            weight = strategy_weights.get(strategy, 0.1)

            for boundary in boundaries:
                if 0 <= boundary <= seq_length:
                    boundary_scores[boundary] += weight

        # é€‰æ‹©é«˜åˆ†è¾¹ç•Œ
        scored_boundaries = [(b, score) for b, score in boundary_scores.items()]
        scored_boundaries.sort(key=lambda x: x[1], reverse=True)

        # é€‰æ‹©å‰Nä¸ªè¾¹ç•Œï¼Œä½†ä¸è¶…è¿‡æœ€å¤§å­—æ®µæ•°
        selected_boundaries = [0]  # èµ·å§‹ä½ç½®

        for boundary, score in scored_boundaries:
            if boundary > 0 and len(selected_boundaries) < self.max_fields:
                # æ£€æŸ¥æ˜¯å¦ä¸å·²é€‰è¾¹ç•Œå¤ªè¿‘
                too_close = False
                for existing in selected_boundaries:
                    if abs(boundary - existing) < self.min_field_size:
                        too_close = True
                        break

                if not too_close:
                    selected_boundaries.append(boundary)

        return sorted(selected_boundaries)

    def _field_validation_and_optimization(self, boundaries_list: List[List[int]],
                                           aligned_sequences: List[bytes],
                                           protocol_name: str) -> List[List[int]]:
        """å­—æ®µéªŒè¯å’Œä¼˜åŒ–"""
        logger.info("   å­—æ®µéªŒè¯å’Œä¼˜åŒ–...")

        optimized_boundaries = []

        for i, boundaries in enumerate(boundaries_list):
            seq = aligned_sequences[i]

            # éªŒè¯å­—æ®µå¤§å°
            validated = self._validate_field_sizes(boundaries, len(seq))

            # åè®®ç‰¹å®šä¼˜åŒ–
            optimized = self._protocol_specific_optimization(validated, seq, protocol_name)

            optimized_boundaries.append(optimized)

        return optimized_boundaries

    def _validate_field_sizes(self, boundaries: List[int], length: int) -> List[int]:
        """éªŒè¯å­—æ®µå¤§å°"""
        if len(boundaries) <= 2:
            return boundaries

        validated = [boundaries[0]]

        for i in range(1, len(boundaries)):
            field_size = boundaries[i] - validated[-1]

            # æ£€æŸ¥å­—æ®µå¤§å°æ˜¯å¦åˆç†
            if field_size >= self.min_field_size:
                validated.append(boundaries[i])
            # å¦‚æœå­—æ®µå¤ªå°ï¼Œåˆå¹¶åˆ°å‰ä¸€ä¸ªå­—æ®µ

        # ç¡®ä¿æœ€åä¸€ä¸ªè¾¹ç•Œæ˜¯åºåˆ—é•¿åº¦
        if validated[-1] != length:
            validated.append(length)

        return validated

    def _protocol_specific_optimization(self, boundaries: List[int], sequence: bytes, protocol_name: str) -> List[int]:
        """åè®®ç‰¹å®šä¼˜åŒ–"""
        if not protocol_name:
            return boundaries

        # é’ˆå¯¹ä¸åŒåè®®çš„ç‰¹å®šä¼˜åŒ–è§„åˆ™
        if protocol_name == 'dns':
            return self._optimize_dns_boundaries(boundaries, sequence)
        elif protocol_name == 'modbus':
            return self._optimize_modbus_boundaries(boundaries, sequence)
        elif protocol_name in ['smb', 'smb2']:
            return self._optimize_smb_boundaries(boundaries, sequence)
        else:
            return boundaries

    def _optimize_dns_boundaries(self, boundaries: List[int], sequence: bytes) -> List[int]:
        """ä¼˜åŒ–DNSè¾¹ç•Œ"""
        # DNSç‰¹å®šçš„ä¼˜åŒ–é€»è¾‘
        # ç¡®ä¿å…³é”®å­—æ®µè¾¹ç•Œå­˜åœ¨
        critical_positions = [2, 4, 6, 8, 10, 12]  # DNSæ ‡å‡†å­—æ®µ

        optimized = list(boundaries)
        for pos in critical_positions:
            if pos < len(sequence) and pos not in optimized:
                optimized.append(pos)

        return sorted(optimized)

    def _optimize_modbus_boundaries(self, boundaries: List[int], sequence: bytes) -> List[int]:
        """ä¼˜åŒ–Modbusè¾¹ç•Œ"""
        # Modbus TCPç‰¹å®šä¼˜åŒ–
        critical_positions = [2, 4, 6, 7, 8]  # Modbusæ ‡å‡†å­—æ®µ

        optimized = list(boundaries)
        for pos in critical_positions:
            if pos < len(sequence) and pos not in optimized:
                optimized.append(pos)

        return sorted(optimized)

    def _optimize_smb_boundaries(self, boundaries: List[int], sequence: bytes) -> List[int]:
        """ä¼˜åŒ–SMBè¾¹ç•Œ"""
        # SMBç‰¹å®šä¼˜åŒ–
        critical_positions = [4, 8, 12, 16] if len(sequence) > 32 else [4, 8]

        optimized = list(boundaries)
        for pos in critical_positions:
            if pos < len(sequence) and pos not in optimized:
                optimized.append(pos)

        return sorted(optimized)


class PrecisionNetzobEvaluator:
    """ç²¾ç¡®ç‰ˆNetzobè¯„ä¼°å™¨ - ä¿®å¤Perfectionè®¡ç®—"""

    def __init__(self):
        self.debug_mode = False

    def evaluate_boundaries(self, predicted_boundaries: List[int],
                            ground_truth_boundaries: List[int],
                            sequence_length: int,
                            debug_info: str = "") -> Dict[str, float]:
        """è¯„ä¼°è¾¹ç•Œæ£€æµ‹æ€§èƒ½ - ä¿®å¤ç‰ˆ"""

        if self.debug_mode:
            logger.debug(f"è¯„ä¼°è¾¹ç•Œ {debug_info}")
            logger.debug(f"  é¢„æµ‹è¾¹ç•Œ: {predicted_boundaries}")
            logger.debug(f"  çœŸå®è¾¹ç•Œ: {ground_truth_boundaries}")
            logger.debug(f"  åºåˆ—é•¿åº¦: {sequence_length}")

        return self._precision_evaluation(predicted_boundaries, ground_truth_boundaries, sequence_length)

    def _precision_evaluation(self, predicted_boundaries: List[int],
                              ground_truth_boundaries: List[int],
                              sequence_length: int) -> Dict[str, float]:
        """ç²¾ç¡®è¯„ä¼°ç®—æ³•"""

        # ç¡®ä¿è¾¹ç•Œåˆ—è¡¨åŒ…å«èµ·å§‹å’Œç»“æŸä½ç½®
        pred_boundaries = sorted(list(set(predicted_boundaries + [0, sequence_length])))
        true_boundaries = sorted(list(set(ground_truth_boundaries + [0, sequence_length])))

        # ç§»é™¤è¶…å‡ºèŒƒå›´çš„è¾¹ç•Œ
        pred_boundaries = [b for b in pred_boundaries if 0 <= b <= sequence_length]
        true_boundaries = [b for b in true_boundaries if 0 <= b <= sequence_length]

        if self.debug_mode:
            logger.debug(f"  æ ‡å‡†åŒ–é¢„æµ‹è¾¹ç•Œ: {pred_boundaries}")
            logger.debug(f"  æ ‡å‡†åŒ–çœŸå®è¾¹ç•Œ: {true_boundaries}")

        # 1. è¾¹ç•Œå‡†ç¡®ç‡ï¼ˆé€ä½ç½®æ¯”è¾ƒï¼‰
        accuracy = self._calculate_position_accuracy(pred_boundaries, true_boundaries, sequence_length)

        # 2. è¾¹ç•Œç²¾ç¡®ç‡å’Œå¬å›ç‡
        precision, recall = self._calculate_boundary_precision_recall(pred_boundaries, true_boundaries)

        # 3. F1åˆ†æ•°
        f1_score = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0

        # 4. å­—æ®µçº§å®Œç¾åŒ¹é…ç‡ï¼ˆå…³é”®ä¿®å¤ï¼‰
        perfection = self._calculate_field_perfection(pred_boundaries, true_boundaries, sequence_length)

        if self.debug_mode:
            logger.debug(f"  å‡†ç¡®ç‡: {accuracy:.4f}")
            logger.debug(f"  ç²¾ç¡®ç‡: {precision:.4f}")
            logger.debug(f"  å¬å›ç‡: {recall:.4f}")
            logger.debug(f"  F1åˆ†æ•°: {f1_score:.4f}")
            logger.debug(f"  å®Œç¾ç‡: {perfection:.4f}")

        return {
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1_score': f1_score,
            'perfection': perfection
        }

    def _calculate_position_accuracy(self, pred_boundaries: List[int],
                                     true_boundaries: List[int],
                                     sequence_length: int) -> float:
        """è®¡ç®—ä½ç½®çº§å‡†ç¡®ç‡"""
        if sequence_length == 0:
            return 1.0

        pred_set = set(pred_boundaries)
        true_set = set(true_boundaries)

        correct_positions = 0
        for pos in range(sequence_length + 1):  # åŒ…å«ç»“æŸä½ç½®
            pred_is_boundary = pos in pred_set
            true_is_boundary = pos in true_set
            if pred_is_boundary == true_is_boundary:
                correct_positions += 1

        return correct_positions / (sequence_length + 1)

    def _calculate_boundary_precision_recall(self, pred_boundaries: List[int],
                                             true_boundaries: List[int]) -> Tuple[float, float]:
        """è®¡ç®—è¾¹ç•Œçº§ç²¾ç¡®ç‡å’Œå¬å›ç‡"""
        pred_set = set(pred_boundaries)
        true_set = set(true_boundaries)

        # ç²¾ç¡®ç‡: é¢„æµ‹çš„è¾¹ç•Œä¸­æœ‰å¤šå°‘æ˜¯æ­£ç¡®çš„
        if len(pred_boundaries) > 0:
            true_positives = len(pred_set & true_set)
            precision = true_positives / len(pred_boundaries)
        else:
            precision = 0.0

        # å¬å›ç‡: çœŸå®è¾¹ç•Œä¸­æœ‰å¤šå°‘è¢«é¢„æµ‹åˆ°
        if len(true_boundaries) > 0:
            true_positives = len(pred_set & true_set)
            recall = true_positives / len(true_boundaries)
        else:
            recall = 1.0 if len(pred_boundaries) == 0 else 0.0

        return precision, recall

    def _calculate_field_perfection(self, pred_boundaries: List[int],
                                    true_boundaries: List[int],
                                    sequence_length: int) -> float:
        """è®¡ç®—å­—æ®µçº§å®Œç¾åŒ¹é…ç‡ - å…³é”®ä¿®å¤"""

        # å°†è¾¹ç•Œè½¬æ¢ä¸ºå­—æ®µèŒƒå›´
        pred_fields = self._boundaries_to_fields(pred_boundaries, sequence_length)
        true_fields = self._boundaries_to_fields(true_boundaries, sequence_length)

        if self.debug_mode:
            logger.debug(f"  é¢„æµ‹å­—æ®µ: {pred_fields}")
            logger.debug(f"  çœŸå®å­—æ®µ: {true_fields}")

        if not true_fields:
            return 1.0 if not pred_fields else 0.0

        # è®¡ç®—å®Œå…¨åŒ¹é…çš„å­—æ®µæ•°
        pred_fields_set = set(pred_fields)
        true_fields_set = set(true_fields)

        perfect_matches = len(pred_fields_set & true_fields_set)
        total_true_fields = len(true_fields_set)

        perfection = perfect_matches / total_true_fields if total_true_fields > 0 else 0.0

        if self.debug_mode:
            logger.debug(f"  å®Œç¾åŒ¹é…å­—æ®µæ•°: {perfect_matches}")
            logger.debug(f"  æ€»çœŸå®å­—æ®µæ•°: {total_true_fields}")

        return perfection

    def _boundaries_to_fields(self, boundaries: List[int], length: int) -> List[Tuple[int, int]]:
        """å°†è¾¹ç•Œè½¬æ¢ä¸ºå­—æ®µèŒƒå›´"""
        if not boundaries:
            return [(0, length)] if length > 0 else []

        fields = []
        boundaries = sorted(list(set(boundaries)))

        # ç¡®ä¿åŒ…å«èµ·å§‹å’Œç»“æŸè¾¹ç•Œ
        if 0 not in boundaries:
            boundaries.insert(0, 0)
        if length not in boundaries:
            boundaries.append(length)

        # ç”Ÿæˆå­—æ®µèŒƒå›´
        for i in range(len(boundaries) - 1):
            start = boundaries[i]
            end = boundaries[i + 1]

            if start < end and start < length:
                fields.append((start, min(end, length)))

        return fields


class ImprovedDatasetExperiment:
    """æ”¹è¿›çš„æ•°æ®é›†å®éªŒç®¡ç†å™¨"""

    def __init__(self, data_root: str = "../../Msg2"):
        self.data_loader = RealDatasetLoader(data_root)
        self.algorithm = EnhancedNetzobAlgorithm()
        self.evaluator = PrecisionNetzobEvaluator()
        self.results = {}
        self.debug_mode = False

    def enable_debug(self):
        """å¯ç”¨è°ƒè¯•æ¨¡å¼"""
        self.debug_mode = True
        self.evaluator.debug_mode = True

    def run_experiments(self, protocols: List[str] = None, sample_limit: int = None):
        """è¿è¡Œå®éªŒ - æ”¹è¿›ç‰ˆ"""
        # è·å–å¯ç”¨åè®®
        available_protocols = self.data_loader.get_available_protocols()

        if protocols is None:
            protocols = available_protocols
        else:
            protocols = [p for p in protocols if p in available_protocols]

        if not protocols:
            logger.error("âŒ æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„åè®®æ•°æ®")
            return

        logger.info("ğŸš€ æ”¹è¿›ç‰ˆNetzobå®éªŒå¼€å§‹")
        logger.info(f"ğŸ“‚ æ•°æ®ç›®å½•: {self.data_loader.data_root}")
        logger.info(f"ğŸ¯ æµ‹è¯•åè®®: {protocols}")
        if sample_limit:
            logger.info(f"ğŸ“Š æ ·æœ¬é™åˆ¶: {sample_limit}")
        logger.info("=" * 70)

        for protocol in protocols:
            logger.info(f"\nğŸ“Š æµ‹è¯•åè®®: {protocol.upper()}")
            logger.info("-" * 50)

            # åŠ è½½çœŸå®æ•°æ®
            data = self.data_loader.load_protocol_data(protocol)

            if not data:
                logger.warning(f"   âŒ è·³è¿‡ {protocol}: æ— æ•°æ®")
                continue

            # é™åˆ¶æ ·æœ¬æ•°é‡ï¼ˆç”¨äºè°ƒè¯•ï¼‰
            if sample_limit and len(data) > sample_limit:
                data = data[:sample_limit]
                logger.info(f"   ğŸ“Š é™åˆ¶æ ·æœ¬æ•°é‡ä¸º: {sample_limit}")

            # è½¬æ¢ä¸ºMessageå¯¹è±¡
            messages = []
            for sample in data:
                msg = Message(sample['raw_data'])
                messages.append(msg)

            try:
                # è¿è¡Œå¢å¼ºç‰ˆNetzobç®—æ³•
                logger.info(f"   ğŸ” è¿è¡Œå¢å¼ºç‰ˆNetzobç®—æ³•...")
                predicted_boundaries = self.algorithm.extract_fields(messages, protocol)

                # è¯„ä¼°æ€§èƒ½
                logger.info(f"   ğŸ“ˆ è¯„ä¼°æ€§èƒ½...")
                all_metrics = []

                for i, (sample, pred_boundaries) in enumerate(zip(data, predicted_boundaries)):
                    true_boundaries = sample['ground_truth_boundaries']
                    length = sample['length']

                    debug_info = f"{protocol}_{i}" if self.debug_mode else ""
                    metrics = self.evaluator.evaluate_boundaries(
                        pred_boundaries, true_boundaries, length, debug_info
                    )
                    all_metrics.append(metrics)

                    # è°ƒè¯•æ¨¡å¼ä¸‹æ˜¾ç¤ºå‰å‡ ä¸ªæ ·æœ¬çš„è¯¦ç»†ä¿¡æ¯
                    if self.debug_mode and i < 3:
                        logger.info(f"   ğŸ” æ ·æœ¬ {i}: é¢„æµ‹è¾¹ç•Œ={pred_boundaries}, çœŸå®è¾¹ç•Œ={true_boundaries}")
                        logger.info(f"        å®Œç¾ç‡={metrics['perfection']:.4f}")

                # è®¡ç®—å¹³å‡æŒ‡æ ‡
                avg_metrics = {}
                for key in ['accuracy', 'precision', 'recall', 'f1_score', 'perfection']:
                    values = [m[key] for m in all_metrics if not np.isnan(m[key])]
                    avg_metrics[key] = np.mean(values) if values else 0.0

                # ä¿å­˜ç»“æœ
                self.results[protocol] = {
                    'sample_count': len(data),
                    'metrics': avg_metrics,
                    'csv_rows': len(data),
                    'individual_metrics': all_metrics  # ä¿å­˜ä¸ªä½“æŒ‡æ ‡ç”¨äºåˆ†æ
                }

                # æ˜¾ç¤ºç»“æœ
                logger.info(f"   âœ… ç»“æœ:")
                logger.info(f"      CSVè¡Œæ•°: {len(data)}")
                logger.info(f"      æ ·æœ¬æ•°é‡: {len(data)}")
                logger.info(f"      å‡†ç¡®ç‡: {avg_metrics['accuracy']:.4f}")
                logger.info(f"      ç²¾ç¡®ç‡: {avg_metrics['precision']:.4f}")
                logger.info(f"      å¬å›ç‡: {avg_metrics['recall']:.4f}")
                logger.info(f"      F1åˆ†æ•°: {avg_metrics['f1_score']:.4f}")
                logger.info(f"      å®Œç¾ç‡: {avg_metrics['perfection']:.4f}")

                # åˆ†æå®Œç¾ç‡åˆ†å¸ƒ
                perfection_values = [m['perfection'] for m in all_metrics]
                perfect_count = sum(1 for p in perfection_values if p >= 0.99)
                logger.info(f"      å®Œç¾åŒ¹é…æ ·æœ¬: {perfect_count}/{len(data)} ({perfect_count / len(data) * 100:.1f}%)")

            except Exception as e:
                logger.error(f"   âŒ å¤„ç† {protocol} æ—¶å‡ºé”™: {e}")
                import traceback
                logger.error(traceback.format_exc())
                self.results[protocol] = {
                    'sample_count': 0,
                    'csv_rows': 0,
                    'metrics': {'accuracy': 0, 'precision': 0, 'recall': 0,
                                'f1_score': 0, 'perfection': 0},
                    'error': str(e)
                }

    def generate_detailed_report(self):
        """ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š"""
        logger.info(f"\n" + "=" * 70)
        logger.info("ğŸ“Š æ”¹è¿›ç‰ˆNetzobå®éªŒè¯¦ç»†æŠ¥å‘Š")
        logger.info("=" * 70)

        if not self.results:
            logger.warning("âŒ æ²¡æœ‰å®éªŒç»“æœ")
            return

        # åˆ›å»ºç»“æœè¡¨æ ¼
        report_data = []
        for protocol, result in self.results.items():
            metrics = result['metrics']
            report_data.append({
                'Protocol': protocol.upper(),
                'CSV_Rows': result.get('csv_rows', 0),
                'Samples': result['sample_count'],
                'Accuracy': f"{metrics['accuracy']:.4f}",
                'Precision': f"{metrics['precision']:.4f}",
                'Recall': f"{metrics['recall']:.4f}",
                'F1-score': f"{metrics['f1_score']:.4f}",
                'Perfection': f"{metrics['perfection']:.4f}"
            })

        # æ˜¾ç¤ºè¡¨æ ¼
        df = pd.DataFrame(report_data)
        print("\næ”¹è¿›ç‰ˆNetzobå®éªŒç»“æœè¡¨æ ¼:")
        print(df.to_string(index=False))

        # è®¡ç®—æ€§èƒ½ç»Ÿè®¡
        logger.info(f"\nğŸ¯ æ€§èƒ½ç»Ÿè®¡:")
        valid_results = [r for r in self.results.values() if 'error' not in r]

        if valid_results:
            total_samples = sum(r['sample_count'] for r in valid_results)
            total_csv_rows = sum(r.get('csv_rows', 0) for r in valid_results)
            avg_perfection = np.mean([r['metrics']['perfection'] for r in valid_results])
            avg_f1 = np.mean([r['metrics']['f1_score'] for r in valid_results])
            avg_accuracy = np.mean([r['metrics']['accuracy'] for r in valid_results])

            logger.info(f"   æ€»CSVè¡Œæ•°: {total_csv_rows}")
            logger.info(f"   æ€»æ ·æœ¬æ•°: {total_samples}")
            logger.info(f"   å¹³å‡å‡†ç¡®ç‡: {avg_accuracy:.4f}")
            logger.info(f"   å¹³å‡F1åˆ†æ•°: {avg_f1:.4f}")
            logger.info(f"   å¹³å‡å®Œç¾ç‡: {avg_perfection:.4f}")

            # åˆ†æå®Œç¾ç‡åˆ†å¸ƒ
            logger.info(f"\nğŸ“ˆ å®Œç¾ç‡åˆ†æ:")
            for protocol, result in self.results.items():
                if 'error' not in result and 'individual_metrics' in result:
                    individual_perfections = [m['perfection'] for m in result['individual_metrics']]
                    perfect_count = sum(1 for p in individual_perfections if p >= 0.99)
                    total_count = len(individual_perfections)
                    logger.info(
                        f"   {protocol.upper()}: {perfect_count}/{total_count} ({perfect_count / total_count * 100:.1f}%) å®Œç¾åŒ¹é…")

        else:
            logger.warning("   æ²¡æœ‰æœ‰æ•ˆçš„å®éªŒç»“æœ")

        # æ”¹è¿›å»ºè®®
        logger.info(f"\nğŸ’¡ æ”¹è¿›å»ºè®®:")
        logger.info("   1. å¦‚æœå®Œç¾ç‡ä»ç„¶è¾ƒä½ï¼Œæ£€æŸ¥ground truthè¾¹ç•Œè§£ææ˜¯å¦æ­£ç¡®")
        logger.info("   2. é’ˆå¯¹ç‰¹å®šåè®®ä¼˜åŒ–è¾¹ç•Œæ£€æµ‹ç­–ç•¥")
        logger.info("   3. è°ƒæ•´ç®—æ³•å‚æ•°ä»¥é€‚åº”æ•°æ®é›†ç‰¹å¾")
        logger.info("   4. è€ƒè™‘ä½¿ç”¨æ›´å¤šçš„è¾¹ç•Œæ£€æµ‹ç­–ç•¥ç»„åˆ")

    def analyze_poor_performance_samples(self, protocol: str, min_samples: int = 5):
        """åˆ†æè¡¨ç°è¾ƒå·®çš„æ ·æœ¬"""
        if protocol not in self.results or 'individual_metrics' not in self.results[protocol]:
            logger.warning(f"   æ²¡æœ‰ {protocol} çš„è¯¦ç»†æŒ‡æ ‡æ•°æ®")
            return

        logger.info(f"\nğŸ” åˆ†æ {protocol.upper()} è¡¨ç°è¾ƒå·®çš„æ ·æœ¬:")

        individual_metrics = self.results[protocol]['individual_metrics']
        poor_samples = [(i, m) for i, m in enumerate(individual_metrics) if m['perfection'] < 0.1]

        logger.info(f"   å‘ç° {len(poor_samples)} ä¸ªå®Œç¾ç‡ < 0.1 çš„æ ·æœ¬")

        if poor_samples and len(poor_samples) <= min_samples:
            for i, metrics in poor_samples[:min_samples]:
                logger.info(f"   æ ·æœ¬ {i}: å®Œç¾ç‡={metrics['perfection']:.4f}, F1={metrics['f1_score']:.4f}")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='æ”¹è¿›ç‰ˆçœŸå®æ•°æ®é›†Netzobå®éªŒ')

    parser.add_argument('--data-root', default='../../Msg2',
                        help='æ•°æ®é›†æ ¹ç›®å½• (é»˜è®¤: ../../Msg2)')

    parser.add_argument('--protocols', nargs='+',
                        choices=['smb', 'smb2', 'dns', 's7comm', 'dnp3',
                                 'modbus', 'ftp', 'tls', 'dhcp'],
                        help='è¦æµ‹è¯•çš„åè®®åˆ—è¡¨')

    parser.add_argument('--debug', action='store_true',
                        help='å¯ç”¨è°ƒè¯•æ¨¡å¼')

    parser.add_argument('--sample-limit', type=int,
                        help='é™åˆ¶æ¯ä¸ªåè®®çš„æ ·æœ¬æ•°é‡ï¼ˆç”¨äºè°ƒè¯•ï¼‰')

    parser.add_argument('--info', action='store_true',
                        help='æ˜¾ç¤ºæ•°æ®é›†ä¿¡æ¯')

    args = parser.parse_args()

    # åˆ›å»ºå®éªŒç®¡ç†å™¨
    experiment = ImprovedDatasetExperiment(args.data_root)

    if args.debug:
        experiment.enable_debug()
        logger.info("ğŸ”§ è°ƒè¯•æ¨¡å¼å·²å¯ç”¨")

    # æ˜¾ç¤ºæ•°æ®é›†ä¿¡æ¯
    if args.info:
        experiment.data_loader.show_data_info()
        return

    logger.info(f"ğŸŒŸ æ”¹è¿›ç‰ˆNetzobå®éªŒè®¾ç½®:")
    logger.info(f"   æ•°æ®æ ¹ç›®å½•: {args.data_root}")
    logger.info(f"   æµ‹è¯•åè®®: {args.protocols or 'ALL'}")
    logger.info(f"   è°ƒè¯•æ¨¡å¼: {args.debug}")
    if args.sample_limit:
        logger.info(f"   æ ·æœ¬é™åˆ¶: {args.sample_limit}")

    # è¿è¡Œå®éªŒ
    experiment.run_experiments(protocols=args.protocols, sample_limit=args.sample_limit)

    # ç”ŸæˆæŠ¥å‘Š
    experiment.generate_detailed_report()

    # åˆ†æè¡¨ç°è¾ƒå·®çš„åè®®
    if args.debug:
        for protocol in experiment.results.keys():
            if 'error' not in experiment.results[protocol]:
                experiment.analyze_poor_performance_samples(protocol)

    logger.info("\nâœ… æ”¹è¿›ç‰ˆNetzobå®éªŒå®Œæˆï¼")
    logger.info("\nğŸ‰ ä¸»è¦æ”¹è¿›:")
    logger.info("   1. ä¿®å¤äº†Perfectionè®¡ç®—ç®—æ³•")
    logger.info("   2. å¢å¼ºäº†è¾¹ç•Œæ£€æµ‹ç­–ç•¥")
    logger.info("   3. æ”¹è¿›äº†åè®®ç‰¹å¼‚æ€§è¾¹ç•Œ")
    logger.info("   4. ä¼˜åŒ–äº†å­—æ®µéªŒè¯é€»è¾‘")
    logger.info("   5. æ·»åŠ äº†è¯¦ç»†çš„è°ƒè¯•åŠŸèƒ½")


if __name__ == "__main__":
    main()